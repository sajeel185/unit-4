{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in c:\\users\\sajee\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "[x] Couldn't link model to 'en'\n",
      "Creating a symlink in spacy/data failed. Make sure you have the required\n",
      "permissions and try re-running the command as admin, or use a virtualenv. You\n",
      "can still import the model as a module and call its load() method, or create the\n",
      "symlink manually.\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\en_core_web_sm\n",
      "-->\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\data\\en\n",
      "[!] Download successful but linking failed\n",
      "Creating a shortcut link for 'en' didn't work (maybe you don't have admin\n",
      "permissions?), but you can still load the model via its full package name: nlp =\n",
      "spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You do not have sufficient privilege to perform this operation.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    \n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text[0:900000]\n",
    "\n",
    "\n",
    "# Import all the Austen in the Project Gutenberg corpus.\n",
    "austen = \"\"\n",
    "for novel in ['persuasion','emma','sense']:\n",
    "    work = gutenberg.raw('austen-' + novel + '.txt')\n",
    "    austen = austen + work\n",
    "\n",
    "# Clean the data.\n",
    "austen_clean = text_cleaner(austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data. This can take some time.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "austen_doc = nlp(austen_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lady', 'russell', 'steady', 'age', 'character', 'extremely', 'provide', 'thought', 'second', 'marriage', 'need', 'apology', 'public', 'apt', 'unreasonably', 'discontent', 'woman', 'marry', 'sir', 'walter', 'continue', 'singleness', 'require', 'explanation']\n",
      "We have 9298 sentences and 900000 tokens.\n"
     ]
    }
   ],
   "source": [
    "# Organize the parsed doc into sentences, while filtering out punctuation\n",
    "# and stop words, and converting words to lower case lemmas.\n",
    "sentences = []\n",
    "for sentence in austen_doc.sents:\n",
    "    sentence = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    sentences.append(sentence)\n",
    "\n",
    "\n",
    "print(sentences[20])\n",
    "print('We have {} sentences and {} tokens.'.format(len(sentences), len(austen_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=10,  # Minimum word count threshold.\n",
    "    window=6,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clay', 0.9573068618774414), ('goddard', 0.9536917209625244), ('musgrove', 0.949884831905365), ('harville', 0.9459196329116821), ('benwick', 0.9432364702224731), ('charles', 0.9112398624420166), ('wentworth', 0.902734637260437), ('hall', 0.9018844962120056), ('croft', 0.8926742076873779), ('colonel', 0.8894760012626648)]\n",
      "0.901502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dinner\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed min_count from 10 to 6, increased size from 300 to 350, and increased window from 6 to 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "model_new_parameters = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=6,  # Minimum word count threshold.\n",
    "    window=9,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=350,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('goddard', 0.9710274934768677), ('jealousy', 0.956786572933197), ('croft', 0.9492164850234985), ('musgrove', 0.9465190172195435), ('clay', 0.9457922577857971), ('hall', 0.9451195001602173), ('cole', 0.9381397366523743), ('repeatedly', 0.9370145797729492), ('acquire', 0.9366686940193176), ('sufficient', 0.9335703253746033)]\n",
      "0.75098747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breakfast\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab_new_parameters = model_new_parameters.wv.vocab.keys()\n",
    "\n",
    "print(model_new_parameters.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model_new_parameters.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model_new_parameters.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing some of the model's hyperparameters, the model didn't improve.  Unlike the original model where some of the answers could have been used in an analogy of man:\"word\" as woman:lady, none of the answers given by the model with the new hyperparameters don't make sense in the analogy to the word \"man\", as we would have hoped.\n",
    "\n",
    "Also, unlike the previous model, the model with the new hyperparameters failed at differentiating the word \"marriage\" from the list of words we had given about different meal times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed min_count from 10 to 14, and decreased window from 6 to 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "model_new_parameters2 = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=14,  # Minimum word count threshold.\n",
    "    window=2,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('goddard', 0.9588110446929932), ('weston', 0.9223220348358154), ('clay', 0.9200819730758667), ('smith', 0.8834136724472046), ('musgrove', 0.8788282871246338), ('hall', 0.8765681982040405), ('croft', 0.8623643517494202), ('colonel', 0.8536821603775024), ('harville', 0.8498642444610596), ('cole', 0.8123654127120972)]\n",
      "0.6091271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dinner\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab_new_parameters2 = model_new_parameters2.wv.vocab.keys()\n",
    "\n",
    "print(model_new_parameters2.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model_new_parameters2.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model_new_parameters2.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I changed the hyperparameters again, but this time I decreased window from 6 to 2, and changed min_count from 10 to 14.  I hoped that by decreasing window from 6 to 2, the model would work better by focusing only on the words immediately next to the target word, but the model actually performed worse.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used negative sampling instead of hierarchical softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "model_neg_sampling = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=10,  # Minimum word count threshold.\n",
    "    window=6,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=0,           # Using negartive sampling.\n",
    "    negative=6\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('enter', 0.9993537664413452), ('highly', 0.9993413686752319), ('wish', 0.9993402361869812), ('friend', 0.9993385076522827), ('meet', 0.9993383884429932), ('anxiety', 0.9993330240249634), ('consciousness', 0.9993325471878052), ('age', 0.9993311166763306), ('listen', 0.9993295669555664), ('appearance', 0.9993287324905396)]\n",
      "0.9996066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breakfast\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab_negative_sampling = model_neg_sampling.wv.vocab.keys()\n",
    "\n",
    "print(model_neg_sampling.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model_neg_sampling.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model_neg_sampling.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Negative Sampling the model was better at catching the similarity between words such as \"Mr.\" and \"Mrs.\", but it still failed to differentiate the word \"marriage\" from the other words that represented meal times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
