{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\sajee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in c:\\users\\sajee\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "[x] Couldn't link model to 'en'\n",
      "Creating a symlink in spacy/data failed. Make sure you have the required\n",
      "permissions and try re-running the command as admin, or use a virtualenv. You\n",
      "can still import the model as a module and call its load() method, or create the\n",
      "symlink manually.\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\en_core_web_sm\n",
      "-->\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\data\\en\n",
      "[!] Download successful but linking failed\n",
      "Creating a shortcut link for 'en' didn't work (maybe you don't have admin\n",
      "permissions?), but you can still load the model via its full package name: nlp =\n",
      "spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You do not have sufficient privilege to perform this operation.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "#getting the list of docs available in gutenberg.\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data from milton-paradise and melville-moby_dick.\n",
    "milton = gutenberg.raw('milton-paradise.txt')\n",
    "melville = gutenberg.raw('melville-moby_dick.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Paradise Lost by John Milton 1667] \n",
      " \n",
      " \n",
      "Book I \n",
      " \n",
      " \n",
      "Of Man's first disobedience, and the fruit \n",
      "Of that forbidden tree whose mortal taste \n",
      "Brought death into the World, and all our woe, \n",
      "With loss of Eden, till one greater Man \n",
      "Restore us, and regain the blissful seat, \n",
      "Sing, Heavenly Muse, that, on the secret top \n",
      "Of Oreb, or of Sinai, didst inspire \n",
      "That shepherd who first taught the chosen see\n"
     ]
    }
   ],
   "source": [
    "#printing milton, uncleaned.\n",
    "print(milton[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Moby Dick by Herman Melville 1851]\n",
      "\n",
      "\n",
      "ETYMOLOGY.\n",
      "\n",
      "(Supplied by a Late Consumptive Usher to a Grammar School)\n",
      "\n",
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.  He was ever dusting his old lexicons and grammars, with a queer\n",
      "handkerchief, mockingly embellished with all the gay flags of all the\n",
      "known nations of the world.  He loved to dust his old grammars; it\n",
      "so\n"
     ]
    }
   ],
   "source": [
    "#printing melville, uncleaned.\n",
    "print(melville[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pattern matches all text between square brackets; using it to get rid of the titles.\n",
    "pattern = \"[\\[].*?[\\]]\"\n",
    "melville = re.sub(pattern, \"\", melville)\n",
    "milton = re.sub(pattern, \"\", milton)\n",
    "\n",
    "# This pattern matches all text between parentheses\n",
    "pattern2 = \"\\\\((.*?)\\\\)\"\n",
    "melville = re.sub(pattern2, \"\", melville)\n",
    "\n",
    "#removing the word \"Etymology\" from the beginning to melville doc\n",
    "pattern3 = \"E[T][Y][M][O][L][O][G][Y][.]\"\n",
    "melville = re.sub(pattern3, \"\", melville)\n",
    "\n",
    "# The Chapter indicator is idiosyncratic r'Book \\d+', so we are removing it.\n",
    "milton = re.sub(r'Book .*', '', milton)\n",
    "melville = re.sub(r'CHAPTER .*', '', melville)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \n",
      "Of Man's first disobedience, and the fruit \n",
      "Of that forbidden tree whose mortal taste \n",
      "Brought death into the World, and all our woe, \n",
      "With loss of Eden, till one greater Man \n",
      "Restore us, and regain the blissful seat, \n",
      "Sing, Heavenly Muse, that, on the secret top \n",
      "Of Oreb, or of Sinai, didst inspire \n",
      "That shepherd who first taught the chosen seed \n",
      "In the beginning how the heavens and ea\n"
     ]
    }
   ],
   "source": [
    "#printing milton with title removed.\n",
    "print(milton[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.  He was ever dusting his old lexicons and grammars, with a queer\n",
      "handkerchief, mockingly embellished with all the gay flags of all the\n",
      "known nations of the world.  He loved to dust his old grammars; it\n",
      "somehow mildly reminded him of his mortality.\n",
      "\n",
      "\"While you take in hand to school others, and to teach t\n"
     ]
    }
   ],
   "source": [
    "#printing melville with title removed.\n",
    "print(melville[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#milton = text_cleaner(milton[:int(len(milton)/10)])\n",
    "#melville = text_cleaner(melville[:int(len(melville)/10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467454\n",
      "1237754\n"
     ]
    }
   ],
   "source": [
    "print(len(milton))\n",
    "print(len(melville))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "milton = text_cleaner(milton)\n",
    "melville = text_cleaner(melville)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455711\n"
     ]
    }
   ],
   "source": [
    "print(len(milton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(milton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of Man's f\n"
     ]
    }
   ],
   "source": [
    "#printing the first 10 characters of milton\n",
    "print(milton[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203942\n"
     ]
    }
   ],
   "source": [
    "print(len(melville))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the rest of the data.\n",
    "austen = gutenberg.raw('austen-emma.txt')\n",
    "blake = gutenberg.raw('blake-poems.txt')\n",
    "bryant = gutenberg.raw('bryant-stories.txt')\n",
    "burgess = gutenberg.raw('burgess-busterbrown.txt')\n",
    "carroll = gutenberg.raw('carroll-alice.txt')\n",
    "chesterton = gutenberg.raw('chesterton-ball.txt')\n",
    "edgeworth = gutenberg.raw('edgeworth-parents.txt')\n",
    "shakespeare = gutenberg.raw('shakespeare-caesar.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Austen and Carroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence o\n"
     ]
    }
   ],
   "source": [
    "print(austen[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
      "conversation?'\n",
      "\n",
      "So she\n"
     ]
    }
   ],
   "source": [
    "print(carroll[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning austen-emma\n",
    "# The Chapter indicator is idiosyncratic\n",
    "austen = re.sub(r'VOLUME \\w+', '', austen)\n",
    "austen = re.sub(r'CHAPTER \\w+', '', austen)\n",
    "\n",
    "# This pattern matches all text between square brackets; using it to get rid of the titles.\n",
    "pattern_removingTitle = \"[\\[].*?[\\]]\"\n",
    "austen = re.sub(pattern_removingTitle, \"\", austen)\n",
    "\n",
    "\n",
    "#cleaning carroll\n",
    "carroll = re.sub(r'CHAPTER .*', '', carroll)\n",
    "\n",
    "# This pattern matches all text between square brackets; using it to get rid of the titles for carroll-alice\n",
    "carroll = re.sub(pattern_removingTitle, \"\", carroll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of h\n"
     ]
    }
   ],
   "source": [
    "print(austen[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
      "conversation?'\n",
      "\n",
      "So she was considering in her own mind (as well as she could, for the\n",
      "hot day made her feel v\n"
     ]
    }
   ],
   "source": [
    "print(carroll[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of austen:  886417\n",
      "<class 'str'>\n",
      "length of austen:  455711\n",
      "\n",
      "lenght of carroll:  143952\n",
      "<class 'str'>\n",
      "length of carroll:  141708\n"
     ]
    }
   ],
   "source": [
    "print(\"lenght of austen: \", len(austen))\n",
    "print(type(austen))\n",
    "\n",
    "#cleaning austen further\n",
    "austen = text_cleaner(milton)\n",
    "\n",
    "print(\"length of austen: \", len(austen))\n",
    "print()\n",
    "print(\"lenght of carroll: \", len(carroll))\n",
    "print(type(carroll))\n",
    "\n",
    "#cleaning austen further\n",
    "carroll = text_cleaner(carroll)\n",
    "\n",
    "print(\"length of carroll: \", len(carroll))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Bryant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stories to Tell to Children by Sara Cone Bryant 1918] \n",
      "\n",
      "\n",
      "TWO LITTLE RIDDLES IN RHYME\n",
      "\n",
      "\n",
      "     There's a garden that I ken,\n",
      "     Full of little gentlemen;\n",
      "     Little caps of blue they wear,\n",
      "     And green ribbons, very fair.\n",
      "           (Flax.)\n",
      "\n",
      "     From house to house he goes,\n",
      "     A messenger small and slight,\n",
      "     And whether it rains or snows,\n",
      "     He sleeps outside in the night.\n"
     ]
    }
   ],
   "source": [
    "print(bryant[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pattern matches all text between square brackets; using it to get rid of the titles.\n",
    "pattern_removingTitle = \"[\\[].*?[\\]]\"\n",
    "bryant = re.sub(pattern_removingTitle, \"\", bryant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "\n",
      "TWO LITTLE RIDDLES IN RHYME\n",
      "\n",
      "\n",
      "     There's a garden that I ken,\n",
      "     Full of little gentlemen;\n",
      "     Little caps of blue they wear,\n",
      "     And green ribbons, very fair.\n",
      "           (Flax.)\n",
      "\n",
      "     From house to house he goes,\n",
      "     A messenger small and slight,\n",
      "     And whether it rains or snows,\n",
      "     He sleeps outside in the night.\n",
      "           (The path.)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE LITTLE YELLOW TU\n"
     ]
    }
   ],
   "source": [
    "print(bryant[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of bryant:  249343\n",
      "<class 'str'>\n",
      "length of bryant:  249343\n"
     ]
    }
   ],
   "source": [
    "print(\"lenght of bryant: \", len(bryant))\n",
    "print(type(bryant))\n",
    "\n",
    "#cleaning bryant further\n",
    "austen = text_cleaner(bryant)\n",
    "\n",
    "print(\"length of bryant: \", len(bryant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Burgess-Busterbrown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Adventures of Buster Bear by Thornton W. Burgess 1920]\n",
      "\n",
      "I\n",
      "\n",
      "BUSTER BEAR GOES FISHING\n",
      "\n",
      "\n",
      "Buster Bear yawned as he lay on his comfortable bed of leaves and\n",
      "watched the first early morning sunbeams creeping through the Green\n",
      "Forest to chase out the Black Shadows. Once more he yawned, and slowly\n",
      "got to his feet and shook himself. Then he walked over to a big\n",
      "pine-tree, stood up on his hi\n"
     ]
    }
   ],
   "source": [
    "print(burgess[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning burgess\n",
    "# This pattern matches all text between square brackets; using it to get rid of the titles.\n",
    "pattern = \"[\\[].*?[\\]]\"\n",
    "burgess = re.sub(pattern, \"\", burgess)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I\n",
      "\n",
      "BUSTER BEAR GOES FISHING\n",
      "\n",
      "\n",
      "Buster Bear yawned as he lay on his comfortable bed of leaves and\n",
      "watched the first early morning sunbeams creeping through the Green\n",
      "Forest to chase out the Black Shadows. Once more he yawned, and slowly\n",
      "got to his feet and shook himself. Then he walked over to a big\n",
      "pine-tree, stood up on his hind legs, reached as high up on the trunk of\n",
      "the tree as he\n"
     ]
    }
   ],
   "source": [
    "print(burgess[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of burgess:  84477\n",
      "<class 'str'>\n",
      "length of burgess:  82341\n"
     ]
    }
   ],
   "source": [
    "print(\"lenght of burgess: \", len(burgess))\n",
    "print(type(burgess))\n",
    "\n",
    "#cleaning burgess further\n",
    "burgess = text_cleaner(burgess)\n",
    "\n",
    "print(\"length of burgess: \", len(burgess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Blake-poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Poems by William Blake 1789]\n",
      "\n",
      " \n",
      "SONGS OF INNOCENCE AND OF EXPERIENCE\n",
      "and THE BOOK of THEL\n",
      "\n",
      "\n",
      " SONGS OF INNOCENCE\n",
      " \n",
      " \n",
      " INTRODUCTION\n",
      " \n",
      " Piping down the valleys wild,\n",
      "   Piping songs of pleasant glee,\n",
      " On a cloud I saw a child,\n",
      "   And he laughing said to me:\n",
      " \n",
      " \"Pipe a song about a Lamb!\"\n",
      "   So I piped with merry cheer.\n",
      " \"Piper, pipe that song again;\"\n",
      "   So I piped: he wept to hear.\n",
      " \n",
      " \"Drop thy pipe\n"
     ]
    }
   ],
   "source": [
    "print(blake[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning blake\n",
    "# This pattern matches all text between square brackets; using it to get rid of the titles.\n",
    "pattern_blake = \"[\\[].*?[\\]]\"\n",
    "blake = re.sub(pattern_blake, \"\", blake)\n",
    "\n",
    "\n",
    "#[\\w*[A-Z]\\w*[A-Z]\\w*]\"\n",
    "\n",
    "pattern2_blake = \"[I][N][T][R][O][D][U][C][T][I][O][N]\"\n",
    "blake = re.sub(pattern2_blake, \"\", blake)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " \n",
      "SONGS OF INNOCENCE AND OF EXPERIENCE\n",
      "and THE BOOK of THEL\n",
      "\n",
      "\n",
      " SONGS OF INNOCENCE\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Piping down the valleys wild,\n",
      "   Piping songs of pleasant glee,\n",
      " On a cloud I saw a child,\n",
      "   And he laughing said to me:\n",
      " \n",
      " \"Pipe a song about a Lamb!\"\n",
      "   So I piped with merry cheer.\n",
      " \"Piper, pipe that song again;\"\n",
      "   So I piped: he wept to hear.\n",
      " \n",
      " \"Drop thy pipe, thy happy pipe;\n",
      "   Sing thy songs of ha\n"
     ]
    }
   ],
   "source": [
    "print(blake[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of blake:  38100\n",
      "<class 'str'>\n",
      "length of blake:  36025\n"
     ]
    }
   ],
   "source": [
    "print(\"lenght of blake: \", len(blake))\n",
    "print(type(blake))\n",
    "\n",
    "#cleaning blake further\n",
    "blake = text_cleaner(blake)\n",
    "\n",
    "print(\"length of blake: \", len(blake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Chesterton-ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Ball and The Cross by G.K. Chesterton 1909]\n",
      "\n",
      "\n",
      "I. A DISCUSSION SOMEWHAT IN THE AIR\n",
      "\n",
      "The flying ship of Professor Lucifer sang through the skies like\n",
      "a silver arrow; the bleak white steel of it, gleaming in the\n",
      "bleak blue emptiness of the evening.  That it was far above the\n",
      "earth was no expression for it; to the two men in it, it seemed\n",
      "to be far above the stars.  The professor had himself inve\n"
     ]
    }
   ],
   "source": [
    "print(chesterton[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning chesterton\n",
    "# This pattern matches all text between square brackets; using it to get rid of the titles.\n",
    "pattern_chesterton = \"[\\[].*?[\\]]\"\n",
    "chesterton = re.sub(pattern_chesterton, \"\", chesterton)\n",
    "\n",
    "\n",
    "\n",
    "#pattern3_chesterton = \"I*\"\n",
    "#chesterton = re.sub(pattern3_chesterton, \"\", chesterton)\n",
    "\n",
    "#pattern4_chesterton = \"\\sV\\s\"\n",
    "#chesterton = re.sub(pattern4_chesterton, \"\", chesterton)\n",
    "\n",
    "#pattern5_chesterton = \"\\sX\\s\"\n",
    "#chesterton = re.sub(pattern5_chesterton, \"\", chesterton)\n",
    "\n",
    "#pattern6_chesterton = \"XV\"\n",
    "#chesterton = re.sub(pattern6_chesterton, \"\", chesterton)\n",
    "\n",
    "#pattern7_chesterton = \"I[V]\"\n",
    "#chesterton = re.sub(pattern6_chesterton, \"\", chesterton)\n",
    "\n",
    "#pattern8_chesterton = \"V[I]*\"\n",
    "#chesterton = re.sub(pattern8_chesterton, \"\", chesterton)\n",
    "\n",
    "#pattern9_chesterton = \"X[I]*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "I. A DISCUSSION SOMEWHAT IN THE AIR\n",
      "\n",
      "The flying ship of Professor Lucifer sang through the skies like\n",
      "a silver arrow; the bleak white steel of it, gleaming in the\n",
      "bleak blue emptiness of the evening.  That it was far above the\n",
      "earth was no expression for it; to the two men in it, it seemed\n",
      "to be far above the stars.  The professor had himself invented\n",
      "the flying machine, and had also invented n\n"
     ]
    }
   ],
   "source": [
    "print(chesterton[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of chesterton:  457337\n",
      "<class 'str'>\n",
      "length of chesterton:  451975\n"
     ]
    }
   ],
   "source": [
    "print(\"lenght of chesterton: \", len(chesterton))\n",
    "print(type(chesterton))\n",
    "\n",
    "#cleaning chesterton further\n",
    "chesterton = text_cleaner(chesterton)\n",
    "\n",
    "print(\"length of chesterton: \", len(chesterton))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning Edgeworth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Parent's Assistant, by Maria Edgeworth]\n",
      "\n",
      "\n",
      "THE ORPHANS.\n",
      "\n",
      "Near the ruins of the castle of Rossmore, in Ireland, is a small cabin,\n",
      "in which there once lived a widow and her four children.  As long as she\n",
      "was able to work, she was very industrious, and was accounted the best\n",
      "spinner in the parish; but she overworked herself at last, and fell ill,\n",
      "so that she could not sit to her wheel as\n"
     ]
    }
   ],
   "source": [
    "print(edgeworth[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning edgeworth\n",
    "# This pattern matches all text between square brackets; using it to get rid of the titles.\n",
    "pattern_edgeworth = \"[\\[].*?[\\]]\"\n",
    "edgeworth = re.sub(pattern_edgeworth, \"\", edgeworth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "THE ORPHANS.\n",
      "\n",
      "Near the ruins of the castle of Rossmore, in Ireland, is a small cabin,\n",
      "in which there once lived a widow and her four children.  As long as she\n",
      "was able to work, she was very industrious, and was accounted the best\n",
      "spinner in the parish; but she overworked herself at last, and fell ill,\n",
      "so that she could not sit to her wheel as she used to do, and was obliged\n",
      "to give it\n"
     ]
    }
   ],
   "source": [
    "print(edgeworth[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of edgeworth:  934977\n",
      "<class 'str'>\n",
      "length of edgeworth:  903897\n"
     ]
    }
   ],
   "source": [
    "print(\"lenght of edgeworth: \", len(edgeworth))\n",
    "print(type(edgeworth))\n",
    "\n",
    "#cleaning edgeworth further\n",
    "edgeworth = text_cleaner(edgeworth)\n",
    "\n",
    "print(\"length of edgeworth: \", len(edgeworth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Julius Caesar by William Shakespeare 1599]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Enter Flauius, Murellus, and certaine Commoners ouer the Stage.\n",
      "\n",
      "  Flauius. Hence: home you idle Creatures, get you home:\n",
      "Is this a Holiday? What, know you not\n",
      "(Being Mechanicall) you ought not walke\n",
      "Vpon a labouring day, without the signe\n",
      "Of your Profession? Speake, what Trade art thou?\n",
      "  Car. Why Sir, a Ca\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning shakespeare\n",
    "# This pattern matches all text between square brackets; using it to get rid of the titles.\n",
    "pattern_shakespeare = \"[\\[].*?[\\]]\"\n",
    "shakespeare = re.sub(pattern_shakespeare, \"\", shakespeare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Enter Flauius, Murellus, and certaine Commoners ouer the Stage.\n",
      "\n",
      "  Flauius. Hence: home you idle Creatures, get you home:\n",
      "Is this a Holiday? What, know you not\n",
      "(Being Mechanicall) you ought not walke\n",
      "Vpon a labouring day, without the signe\n",
      "Of your Profession? Speake, what Trade art thou?\n",
      "  Car. Why Sir, a Carpenter\n",
      "\n",
      "   Mur. Where is thy Leather Apron, and thy Rule?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of shakespeare:  112245\n",
      "<class 'str'>\n",
      "length of shakespeare:  109364\n"
     ]
    }
   ],
   "source": [
    "print(\"length of shakespeare: \", len(shakespeare))\n",
    "print(type(shakespeare))\n",
    "\n",
    "#cleaning shakespeare further\n",
    "shakespeare = text_cleaner(shakespeare)\n",
    "\n",
    "print(\"length of shakespeare: \", len(shakespeare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "milton length:  1873\n",
      "melville length:  10279\n",
      "austen length:  2725\n",
      "blake length:  355\n",
      "bryant length:  2725\n",
      "burgess length:  1018\n",
      "carroll length:  1629\n",
      "chesterton length:  4865\n",
      "edgeworth length:  11130\n",
      "shakespeare length:  1614\n"
     ]
    }
   ],
   "source": [
    "#splitting each sentence in milton into a list of strings\n",
    "milton_sent_list = re.split('[?.!]', milton)\n",
    "print(\"milton length: \", len(milton_sent_list))\n",
    "\n",
    "#splitting each sentence in melville into a list of strings.\n",
    "melville_sent_list = re.split('[?.!]', melville)\n",
    "print(\"melville length: \", len(melville_sent_list))\n",
    "\n",
    "#splitting each sentence in austen into a list of strings.\n",
    "austen_sent_list = re.split('[?.!]', austen)\n",
    "print(\"austen length: \", len(austen_sent_list))\n",
    "\n",
    "#splitting each sentence in blake into a list of strings.\n",
    "blake_sent_list = re.split('[?.!]', blake)\n",
    "print(\"blake length: \", len(blake_sent_list))\n",
    "\n",
    "#splitting each sentence in bryant into a list of strings.\n",
    "bryant_sent_list = re.split('[?.!]', bryant)\n",
    "print(\"bryant length: \", len(bryant_sent_list))\n",
    "\n",
    "#splitting each sentence in burgess into a list of strings.\n",
    "burgess_sent_list = re.split('[?.!]', burgess)\n",
    "print(\"burgess length: \", len(burgess_sent_list))\n",
    "\n",
    "#splitting each sentence in carroll into a list of strings.\n",
    "carroll_sent_list = re.split('[?.!]', carroll)\n",
    "print(\"carroll length: \", len(carroll_sent_list))\n",
    "\n",
    "#splitting each sentence in chesterton into a list of strings.\n",
    "chesterton_sent_list = re.split('[?.!]', chesterton)\n",
    "print(\"chesterton length: \", len(chesterton_sent_list))\n",
    "\n",
    "#splitting each sentence in melville into a list of strings.\n",
    "edgeworth_sent_list = re.split('[?.!]', edgeworth)\n",
    "print(\"edgeworth length: \", len(edgeworth_sent_list))\n",
    "\n",
    "#splitting each sentence in melville into a list of strings.\n",
    "shakespeare_sent_list = re.split('[?.!]', shakespeare)\n",
    "print(\"shakespeare length: \", len(shakespeare_sent_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(milton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing milton into ten separate parts\n",
    "milton_20 = milton_sent_list[0:20]\n",
    "milton_40 = milton_sent_list[20:40]\n",
    "milton_60 = milton_sent_list[40:60]\n",
    "milton_80 = milton_sent_list[60:80]\n",
    "milton_100 = milton_sent_list[80:100]\n",
    "milton_120 = milton_sent_list[100:120]\n",
    "milton_140 = milton_sent_list[120:140]\n",
    "milton_160 = milton_sent_list[140:160]\n",
    "milton_180 = milton_sent_list[160:180]\n",
    "milton_210 = milton_sent_list[180:210]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing austen into ten separate parts\n",
    "austen_30 = austen_sent_list[0:30]\n",
    "austen_60 = austen_sent_list[30:60]\n",
    "austen_90 = austen_sent_list[60:90]\n",
    "austen_120 = austen_sent_list[90:120]\n",
    "austen_150 = austen_sent_list[120:150]\n",
    "austen_180 = austen_sent_list[150:180]\n",
    "austen_210 = austen_sent_list[180:210]\n",
    "austen_240 = austen_sent_list[210:240]\n",
    "austen_270 = austen_sent_list[240:270]\n",
    "austen_300 = austen_sent_list[270:300]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing melville into ten separate parts\n",
    "melville_30 = melville_sent_list[0:30]\n",
    "melville_60 = melville_sent_list[30:60]\n",
    "melville_90 = melville_sent_list[60:90]\n",
    "melville_120 = melville_sent_list[90:120]\n",
    "melville_150 = melville_sent_list[120:150]\n",
    "melville_180 = melville_sent_list[150:180]\n",
    "melville_210 = melville_sent_list[180:210]\n",
    "melville_240 = melville_sent_list[210:240]\n",
    "melville_270 = melville_sent_list[240:270]\n",
    "melville_300 = melville_sent_list[270:300]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing blake into ten separate parts\n",
    "blake_30 = blake_sent_list[0:30]\n",
    "blake_60 = blake_sent_list[30:60]\n",
    "blake_90 = blake_sent_list[60:90]\n",
    "blake_120 = blake_sent_list[90:120]\n",
    "blake_150 = blake_sent_list[120:150]\n",
    "blake_180 = blake_sent_list[150:180]\n",
    "blake_210 = blake_sent_list[180:210]\n",
    "blake_240 = blake_sent_list[210:240]\n",
    "blake_270 = blake_sent_list[240:270]\n",
    "blake_300 = blake_sent_list[270:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing bryant into ten separate parts\n",
    "bryant_30 = bryant_sent_list[0:30]\n",
    "bryant_60 = bryant_sent_list[30:60]\n",
    "bryant_90 = bryant_sent_list[60:90]\n",
    "bryant_120 = bryant_sent_list[90:120]\n",
    "bryant_150 = bryant_sent_list[120:150]\n",
    "bryant_180 = bryant_sent_list[150:180]\n",
    "bryant_210 = bryant_sent_list[180:210]\n",
    "bryant_240 = bryant_sent_list[210:240]\n",
    "bryant_270 = bryant_sent_list[240:270]\n",
    "bryant_300 = bryant_sent_list[270:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing burgess into ten separate parts\n",
    "burgess_30 = burgess_sent_list[0:30]\n",
    "burgess_60 = burgess_sent_list[30:60]\n",
    "burgess_90 = burgess_sent_list[60:90]\n",
    "burgess_120 = burgess_sent_list[90:120]\n",
    "burgess_150 = burgess_sent_list[120:150]\n",
    "burgess_180 = burgess_sent_list[150:180]\n",
    "burgess_210 = burgess_sent_list[180:210]\n",
    "burgess_240 = burgess_sent_list[210:240]\n",
    "burgess_270 = burgess_sent_list[240:270]\n",
    "burgess_300 = burgess_sent_list[270:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing carroll into ten separate parts\n",
    "carroll_30 = carroll_sent_list[0:30]\n",
    "carroll_60 = carroll_sent_list[30:60]\n",
    "carroll_90 = carroll_sent_list[60:90]\n",
    "carroll_120 = carroll_sent_list[90:120]\n",
    "carroll_150 = carroll_sent_list[120:150]\n",
    "carroll_180 = carroll_sent_list[150:180]\n",
    "carroll_210 = carroll_sent_list[180:210]\n",
    "carroll_240 = carroll_sent_list[210:240]\n",
    "carroll_270 = carroll_sent_list[240:270]\n",
    "carroll_300 = carroll_sent_list[270:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing chesterton into ten separate parts\n",
    "chesterton_30 = chesterton_sent_list[0:30]\n",
    "chesterton_60 = chesterton_sent_list[30:60]\n",
    "chesterton_90 = chesterton_sent_list[60:90]\n",
    "chesterton_120 = chesterton_sent_list[90:120]\n",
    "chesterton_150 = chesterton_sent_list[120:150]\n",
    "chesterton_180 = chesterton_sent_list[150:180]\n",
    "chesterton_210 = chesterton_sent_list[180:210]\n",
    "chesterton_240 = chesterton_sent_list[210:240]\n",
    "chesterton_270 = chesterton_sent_list[240:270]\n",
    "chesterton_300 = chesterton_sent_list[270:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing edgeworth into ten separate parts\n",
    "edgeworth_30 = edgeworth_sent_list[0:30]\n",
    "edgeworth_60 = edgeworth_sent_list[30:60]\n",
    "edgeworth_90 = edgeworth_sent_list[60:90]\n",
    "edgeworth_120 = edgeworth_sent_list[90:120]\n",
    "edgeworth_150 = edgeworth_sent_list[120:150]\n",
    "edgeworth_180 = edgeworth_sent_list[150:180]\n",
    "edgeworth_210 = edgeworth_sent_list[180:210]\n",
    "edgeworth_240 = edgeworth_sent_list[210:240]\n",
    "edgeworth_270 = edgeworth_sent_list[240:270]\n",
    "edgeworth_300 = edgeworth_sent_list[270:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing shakespeare into ten separate parts\n",
    "shakespeare_30 = shakespeare_sent_list[0:30]\n",
    "shakespeare_60 = shakespeare_sent_list[30:60]\n",
    "shakespeare_90 = shakespeare_sent_list[60:90]\n",
    "shakespeare_120 = shakespeare_sent_list[90:120]\n",
    "shakespeare_150 = shakespeare_sent_list[120:150]\n",
    "shakespeare_180 = shakespeare_sent_list[150:180]\n",
    "shakespeare_210 = shakespeare_sent_list[180:210]\n",
    "shakespeare_240 = shakespeare_sent_list[210:240]\n",
    "shakespeare_270 = shakespeare_sent_list[240:270]\n",
    "shakespeare_300 = shakespeare_sent_list[270:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame()\n",
    "\n",
    "#df1 = .....\n",
    "\n",
    "#df.append(df1)\n",
    "\n",
    "#df_milton1.to_csv(y+\".csv\")\n",
    "\n",
    "#variablefiles = [\"milton20\", 'milton30']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#milton_separated = [milton_20, milton_40, milton_60, milton_80, milton_100, milton_120, \n",
    "#                    milton_140, milton_160, milton_180, milton_210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_names = ['sentences', 'author']\n",
    "#for x in milton_separated:\n",
    "#    dfname = pd.DataFrame(columns=column_names)\n",
    "#    dfname['sentences'] = x\n",
    "#    dfname['author'] = \"milton\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentences  author\n",
      "0   Of Man's first disobedience, and the fruit Of ...  milton\n",
      "1    And chiefly thou, O Spirit, that dost prefer ...  milton\n",
      "2    Say first for Heaven hides nothing from thy v...  milton\n",
      "3          Who first seduced them to that foul revolt  milton\n",
      "4    Th' infernal Serpent; he it was whose guile, ...  milton\n",
      "5    Him the Almighty Power Hurled headlong flamin...  milton\n",
      "6    Nine times the space that measures day and ni...  milton\n",
      "7    But his doom Reserved him to more wrath; for ...  milton\n",
      "8    At once, as far as Angels ken, he views The d...  milton\n",
      "9    A dungeon horrible, on all sides round, As on...  milton\n",
      "10   Such place Eternal Justice has prepared For t...  milton\n",
      "11      Oh how unlike the place from whence they fell  milton\n",
      "12   There the companions of his fall, o'erwhelmed...  milton\n",
      "13   To whom th' Arch-Enemy, And thence in Heaven ...  milton\n",
      "14   how changed From him who, in the happy realms...  milton\n",
      "15   if he whom mutual league, United thoughts and...  milton\n",
      "16   Yet not for those, Nor what the potent Victor...  milton\n",
      "17                      What though the field be lost  milton\n",
      "18   All is not lost the unconquerable will, And s...  milton\n",
      "19   That glory never shall his wrath or might Ext...  milton\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for milton\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_milton1 = pd.DataFrame(columns=column_names)\n",
    "df_milton1['sentences'] = milton_20\n",
    "df_milton1['author'] = \"milton\"\n",
    "\n",
    "df_milton2 = pd.DataFrame(columns=column_names)\n",
    "df_milton2['sentences'] = milton_40\n",
    "df_milton2['author'] = \"milton\"\n",
    "\n",
    "df_milton3 = pd.DataFrame(columns=column_names)\n",
    "df_milton3['sentences'] = milton_60\n",
    "df_milton3['author'] = \"milton\"\n",
    "\n",
    "df_milton4 = pd.DataFrame(columns=column_names)\n",
    "df_milton4['sentences'] = milton_80\n",
    "df_milton4['author'] = \"milton\"\n",
    "\n",
    "df_milton5 = pd.DataFrame(columns=column_names)\n",
    "df_milton5['sentences'] = milton_100\n",
    "df_milton5['author'] = \"milton\"\n",
    "\n",
    "df_milton6 = pd.DataFrame(columns=column_names)\n",
    "df_milton6['sentences'] = milton_120\n",
    "df_milton6['author'] = \"milton\"\n",
    "\n",
    "df_milton7 = pd.DataFrame(columns=column_names)\n",
    "df_milton7['sentences'] = milton_140\n",
    "df_milton7['author'] = \"milton\"\n",
    "\n",
    "df_milton8 = pd.DataFrame(columns=column_names)\n",
    "df_milton8['sentences'] = milton_160\n",
    "df_milton8['author'] = \"milton\"\n",
    "\n",
    "df_milton9 = pd.DataFrame(columns=column_names)\n",
    "df_milton9['sentences'] = milton_180\n",
    "df_milton9['author'] = \"milton\"\n",
    "\n",
    "df_milton10 = pd.DataFrame(columns=column_names)\n",
    "df_milton10['sentences'] = milton_210\n",
    "df_milton10['author'] = \"milton\"\n",
    "\n",
    "\n",
    "print(df_milton1.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences    author\n",
      "0  The pale Usher threadbare in coat, heart, body...  melville\n",
      "1   He was ever dusting his old lexicons and gram...  melville\n",
      "2   He loved to dust his old grammars; it somehow...  melville\n",
      "3   \"While you take in hand to school others, and...  melville\n",
      "4                                  \" HACKLUYT \"WHALE  melville\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for melville\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_melville1 = pd.DataFrame(columns=column_names)\n",
    "df_melville1['sentences'] = melville_30\n",
    "df_melville1['author'] = \"melville\"\n",
    "\n",
    "df_melville2 = pd.DataFrame(columns=column_names)\n",
    "df_melville2['sentences'] = melville_60\n",
    "df_melville2['author'] = \"melville\"\n",
    "\n",
    "df_melville3 = pd.DataFrame(columns=column_names)\n",
    "df_melville3['sentences'] = melville_90\n",
    "df_melville3['author'] = \"melville\"\n",
    "\n",
    "df_melville4 = pd.DataFrame(columns=column_names)\n",
    "df_melville4['sentences'] = melville_120\n",
    "df_melville4['author'] = \"melville\"\n",
    "\n",
    "df_melville5 = pd.DataFrame(columns=column_names)\n",
    "df_melville5['sentences'] = melville_150\n",
    "df_melville5['author'] = \"melville\"\n",
    "\n",
    "df_melville6 = pd.DataFrame(columns=column_names)\n",
    "df_melville6['sentences'] = melville_180\n",
    "df_melville6['author'] = \"melville\"\n",
    "\n",
    "df_melville7 = pd.DataFrame(columns=column_names)\n",
    "df_melville7['sentences'] = melville_210\n",
    "df_melville7['author'] = \"melville\"\n",
    "\n",
    "df_melville8 = pd.DataFrame(columns=column_names)\n",
    "df_melville8['sentences'] = melville_240\n",
    "df_melville8['author'] = \"melville\"\n",
    "\n",
    "df_melville9 = pd.DataFrame(columns=column_names)\n",
    "df_melville9['sentences'] = melville_270\n",
    "df_melville9['author'] = \"melville\"\n",
    "\n",
    "df_melville10 = pd.DataFrame(columns=column_names)\n",
    "df_melville10['sentences'] = melville_300\n",
    "df_melville10['author'] = \"melville\"\n",
    "\n",
    "\n",
    "print(df_melville1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences  author\n",
      "0  TWO LITTLE RIDDLES IN RHYME There's a garden t...  austen\n",
      "1                                              (Flax  austen\n",
      "2  ) From house to house he goes, A messenger sma...  austen\n",
      "3                                          (The path  austen\n",
      "4  ) THE LITTLE YELLOW TULIP Once there was a lit...  austen\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for austen\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_austen1 = pd.DataFrame(columns=column_names)\n",
    "df_austen1['sentences'] = austen_30\n",
    "df_austen1['author'] = \"austen\"\n",
    "\n",
    "df_austen2 = pd.DataFrame(columns=column_names)\n",
    "df_austen2['sentences'] = austen_60\n",
    "df_austen2['author'] = \"austen\"\n",
    "\n",
    "df_austen3 = pd.DataFrame(columns=column_names)\n",
    "df_austen3['sentences'] = austen_90\n",
    "df_austen3['author'] = \"austen\"\n",
    "\n",
    "df_austen4 = pd.DataFrame(columns=column_names)\n",
    "df_austen4['sentences'] = austen_120\n",
    "df_austen4['author'] = \"austen\"\n",
    "\n",
    "df_austen5 = pd.DataFrame(columns=column_names)\n",
    "df_austen5['sentences'] = austen_150\n",
    "df_austen5['author'] = \"austen\"\n",
    "\n",
    "df_austen6 = pd.DataFrame(columns=column_names)\n",
    "df_austen6['sentences'] = austen_180\n",
    "df_austen6['author'] = \"austen\"\n",
    "\n",
    "df_austen7 = pd.DataFrame(columns=column_names)\n",
    "df_austen7['sentences'] = austen_210\n",
    "df_austen7['author'] = \"austen\"\n",
    "\n",
    "df_austen8 = pd.DataFrame(columns=column_names)\n",
    "df_austen8['sentences'] = austen_240\n",
    "df_austen8['author'] = \"austen\"\n",
    "\n",
    "df_austen9 = pd.DataFrame(columns=column_names)\n",
    "df_austen9['sentences'] = austen_270\n",
    "df_austen9['author'] = \"austen\"\n",
    "\n",
    "df_austen10 = pd.DataFrame(columns=column_names)\n",
    "df_austen10['sentences'] = austen_300\n",
    "df_austen10['author'] = \"austen\"\n",
    "\n",
    "\n",
    "print(df_austen1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences author\n",
      "0  SONGS OF INNOCENCE AND OF EXPERIENCE and THE B...  blake\n",
      "1                      \" So I piped with merry cheer  blake\n",
      "2   \"Piper, pipe that song again;\" So I piped: he...  blake\n",
      "3   \"Drop thy pipe, thy happy pipe; Sing thy song...  blake\n",
      "4  \" So I sang the same again, While he wept with...  blake\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for blake\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_blake1 = pd.DataFrame(columns=column_names)\n",
    "df_blake1['sentences'] = blake_30\n",
    "df_blake1['author'] = \"blake\"\n",
    "\n",
    "df_blake2 = pd.DataFrame(columns=column_names)\n",
    "df_blake2['sentences'] = blake_60\n",
    "df_blake2['author'] = \"blake\"\n",
    "\n",
    "df_blake3 = pd.DataFrame(columns=column_names)\n",
    "df_blake3['sentences'] = blake_90\n",
    "df_blake3['author'] = \"blake\"\n",
    "\n",
    "df_blake4 = pd.DataFrame(columns=column_names)\n",
    "df_blake4['sentences'] = blake_120\n",
    "df_blake4['author'] = \"blake\"\n",
    "\n",
    "df_blake5 = pd.DataFrame(columns=column_names)\n",
    "df_blake5['sentences'] = blake_150\n",
    "df_blake5['author'] = \"blake\"\n",
    "\n",
    "df_blake6 = pd.DataFrame(columns=column_names)\n",
    "df_blake6['sentences'] = blake_180\n",
    "df_blake6['author'] = \"blake\"\n",
    "\n",
    "df_blake7 = pd.DataFrame(columns=column_names)\n",
    "df_blake7['sentences'] = blake_210\n",
    "df_blake7['author'] = \"blake\"\n",
    "\n",
    "df_blake8 = pd.DataFrame(columns=column_names)\n",
    "df_blake8['sentences'] = blake_240\n",
    "df_blake8['author'] = \"blake\"\n",
    "\n",
    "df_blake9 = pd.DataFrame(columns=column_names)\n",
    "df_blake9['sentences'] = blake_270\n",
    "df_blake9['author'] = \"blake\"\n",
    "\n",
    "df_blake10 = pd.DataFrame(columns=column_names)\n",
    "df_blake10['sentences'] = blake_300\n",
    "df_blake10['author'] = \"blake\"\n",
    "\n",
    "\n",
    "print(df_blake1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences  author\n",
      "0   \\r\\n\\r\\n\\r\\nTWO LITTLE RIDDLES IN RHYME\\r\\n\\r...  bryant\n",
      "1                               \\r\\n           (Flax  bryant\n",
      "2  )\\r\\n\\r\\n     From house to house he goes,\\r\\n...  bryant\n",
      "3                           \\r\\n           (The path  bryant\n",
      "4  )\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nTHE LITTLE YELLOW TULIP\\r...  bryant\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for bryant\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_bryant1 = pd.DataFrame(columns=column_names)\n",
    "df_bryant1['sentences'] = bryant_30\n",
    "df_bryant1['author'] = \"bryant\"\n",
    "\n",
    "df_bryant2 = pd.DataFrame(columns=column_names)\n",
    "df_bryant2['sentences'] = bryant_60\n",
    "df_bryant2['author'] = \"bryant\"\n",
    "\n",
    "df_bryant3 = pd.DataFrame(columns=column_names)\n",
    "df_bryant3['sentences'] = bryant_90\n",
    "df_bryant3['author'] = \"bryant\"\n",
    "\n",
    "df_bryant4 = pd.DataFrame(columns=column_names)\n",
    "df_bryant4['sentences'] = bryant_120\n",
    "df_bryant4['author'] = \"bryant\"\n",
    "\n",
    "df_bryant5 = pd.DataFrame(columns=column_names)\n",
    "df_bryant5['sentences'] = bryant_150\n",
    "df_bryant5['author'] = \"bryant\"\n",
    "\n",
    "df_bryant6 = pd.DataFrame(columns=column_names)\n",
    "df_bryant6['sentences'] = bryant_180\n",
    "df_bryant6['author'] = \"bryant\"\n",
    "\n",
    "df_bryant7 = pd.DataFrame(columns=column_names)\n",
    "df_bryant7['sentences'] = bryant_210\n",
    "df_bryant7['author'] = \"bryant\"\n",
    "\n",
    "df_bryant8 = pd.DataFrame(columns=column_names)\n",
    "df_bryant8['sentences'] = bryant_240\n",
    "df_bryant8['author'] = \"bryant\"\n",
    "\n",
    "df_bryant9 = pd.DataFrame(columns=column_names)\n",
    "df_bryant9['sentences'] = bryant_270\n",
    "df_bryant9['author'] = \"bryant\"\n",
    "\n",
    "df_bryant10 = pd.DataFrame(columns=column_names)\n",
    "df_bryant10['sentences'] = bryant_300\n",
    "df_bryant10['author'] = \"bryant\"\n",
    "\n",
    "\n",
    "print(df_bryant1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences   author\n",
      "0  I BUSTER BEAR GOES FISHING Buster Bear yawned ...  burgess\n",
      "1   Once more he yawned, and slowly got to his fe...  burgess\n",
      "2   Then he walked over to a big pine-tree, stood...  burgess\n",
      "3   After that he yawned until it seemed as if hi...  burgess\n",
      "4   While he sat there, trying to make up his min...  burgess\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for burgess\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_burgess1 = pd.DataFrame(columns=column_names)\n",
    "df_burgess1['sentences'] = burgess_30\n",
    "df_burgess1['author'] = \"burgess\"\n",
    "\n",
    "df_burgess2 = pd.DataFrame(columns=column_names)\n",
    "df_burgess2['sentences'] = burgess_60\n",
    "df_burgess2['author'] = \"burgess\"\n",
    "\n",
    "df_burgess3 = pd.DataFrame(columns=column_names)\n",
    "df_burgess3['sentences'] = burgess_90\n",
    "df_burgess3['author'] = \"burgess\"\n",
    "\n",
    "df_burgess4 = pd.DataFrame(columns=column_names)\n",
    "df_burgess4['sentences'] = burgess_120\n",
    "df_burgess4['author'] = \"burgess\"\n",
    "\n",
    "df_burgess5 = pd.DataFrame(columns=column_names)\n",
    "df_burgess5['sentences'] = burgess_150\n",
    "df_burgess5['author'] = \"burgess\"\n",
    "\n",
    "df_burgess6 = pd.DataFrame(columns=column_names)\n",
    "df_burgess6['sentences'] = burgess_180\n",
    "df_burgess6['author'] = \"burgess\"\n",
    "\n",
    "df_burgess7 = pd.DataFrame(columns=column_names)\n",
    "df_burgess7['sentences'] = burgess_210\n",
    "df_burgess7['author'] = \"burgess\"\n",
    "\n",
    "df_burgess8 = pd.DataFrame(columns=column_names)\n",
    "df_burgess8['sentences'] = burgess_240\n",
    "df_burgess8['author'] = \"burgess\"\n",
    "\n",
    "df_burgess9 = pd.DataFrame(columns=column_names)\n",
    "df_burgess9['sentences'] = burgess_270\n",
    "df_burgess9['author'] = \"burgess\"\n",
    "\n",
    "df_burgess10 = pd.DataFrame(columns=column_names)\n",
    "df_burgess10['sentences'] = burgess_300\n",
    "df_burgess10['author'] = \"burgess\"\n",
    "\n",
    "\n",
    "print(df_burgess1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences   author\n",
      "0  Alice was beginning to get very tired of sitti...  carroll\n",
      "1  ' So she was considering in her own mind (as w...  carroll\n",
      "2   There was nothing so VERY remarkable in that;...  carroll\n",
      "3                                            Oh dear  carroll\n",
      "4                                    I shall be late  carroll\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for carroll\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_carroll1 = pd.DataFrame(columns=column_names)\n",
    "df_carroll1['sentences'] = carroll_30\n",
    "df_carroll1['author'] = \"carroll\"\n",
    "\n",
    "df_carroll2 = pd.DataFrame(columns=column_names)\n",
    "df_carroll2['sentences'] = carroll_60\n",
    "df_carroll2['author'] = \"carroll\"\n",
    "\n",
    "df_carroll3 = pd.DataFrame(columns=column_names)\n",
    "df_carroll3['sentences'] = carroll_90\n",
    "df_carroll3['author'] = \"carroll\"\n",
    "\n",
    "df_carroll4 = pd.DataFrame(columns=column_names)\n",
    "df_carroll4['sentences'] = carroll_120\n",
    "df_carroll4['author'] = \"carroll\"\n",
    "\n",
    "df_carroll5 = pd.DataFrame(columns=column_names)\n",
    "df_carroll5['sentences'] = carroll_150\n",
    "df_carroll5['author'] = \"carroll\"\n",
    "\n",
    "df_carroll6 = pd.DataFrame(columns=column_names)\n",
    "df_carroll6['sentences'] = carroll_180\n",
    "df_carroll6['author'] = \"carroll\"\n",
    "\n",
    "df_carroll7 = pd.DataFrame(columns=column_names)\n",
    "df_carroll7['sentences'] = carroll_210\n",
    "df_carroll7['author'] = \"carroll\"\n",
    "\n",
    "df_carroll8 = pd.DataFrame(columns=column_names)\n",
    "df_carroll8['sentences'] = carroll_240\n",
    "df_carroll8['author'] = \"carroll\"\n",
    "\n",
    "df_carroll9 = pd.DataFrame(columns=column_names)\n",
    "df_carroll9['sentences'] = carroll_270\n",
    "df_carroll9['author'] = \"carroll\"\n",
    "\n",
    "df_carroll10 = pd.DataFrame(columns=column_names)\n",
    "df_carroll10['sentences'] = carroll_300\n",
    "df_carroll10['author'] = \"carroll\"\n",
    "\n",
    "\n",
    "print(df_carroll1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences      author\n",
      "0                                                  I  chesterton\n",
      "1   A DISCUSSION SOMEWHAT IN THE AIR The flying s...  chesterton\n",
      "2   That it was far above the earth was no expres...  chesterton\n",
      "3   The professor had himself invented the flying...  chesterton\n",
      "4   Every sort of tool or apparatus had, in conse...  chesterton\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for chesterton\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_chesterton1 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton1['sentences'] = chesterton_30\n",
    "df_chesterton1['author'] = \"chesterton\"\n",
    "\n",
    "df_chesterton2 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton2['sentences'] = chesterton_60\n",
    "df_chesterton2['author'] = \"chesterton\"\n",
    "\n",
    "df_chesterton3 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton3['sentences'] = chesterton_90\n",
    "df_chesterton3['author'] = \"chesterton\"\n",
    "\n",
    "df_chesterton4 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton4['sentences'] = chesterton_120\n",
    "df_chesterton4['author'] = \"chesterton\"\n",
    "\n",
    "df_chesterton5 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton5['sentences'] = chesterton_150\n",
    "df_chesterton5['author'] = \"chesterton\"\n",
    "\n",
    "df_chesterton6 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton6['sentences'] = chesterton_180\n",
    "df_chesterton6['author'] = \"chesterton\"\n",
    "\n",
    "df_chesterton7 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton7['sentences'] = chesterton_210\n",
    "df_chesterton7['author'] = \"chesterton\"\n",
    "\n",
    "df_chesterton8 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton8['sentences'] = chesterton_240\n",
    "df_chesterton8['author'] = \"chesterton\"\n",
    "\n",
    "df_chesterton9 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton9['sentences'] = chesterton_270\n",
    "df_chesterton9['author'] = \"chesterton\"\n",
    "\n",
    "df_chesterton10 = pd.DataFrame(columns=column_names)\n",
    "df_chesterton10['sentences'] = chesterton_300\n",
    "df_chesterton10['author'] = \"chesterton\"\n",
    "\n",
    "\n",
    "print(df_chesterton1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences     author\n",
      "0                                        THE ORPHANS  edgeworth\n",
      "1   Near the ruins of the castle of Rossmore, in ...  edgeworth\n",
      "2   As long as she was able to work, she was very...  edgeworth\n",
      "3       Mary was at this time about twelve years old  edgeworth\n",
      "4   One evening she was sitting at the foot of he...  edgeworth\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for edgeworth\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_edgeworth1 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth1['sentences'] = edgeworth_30\n",
    "df_edgeworth1['author'] = \"edgeworth\"\n",
    "\n",
    "df_edgeworth2 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth2['sentences'] = edgeworth_60\n",
    "df_edgeworth2['author'] = \"edgeworth\"\n",
    "\n",
    "df_edgeworth3 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth3['sentences'] = edgeworth_90\n",
    "df_edgeworth3['author'] = \"edgeworth\"\n",
    "\n",
    "df_edgeworth4 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth4['sentences'] = edgeworth_120\n",
    "df_edgeworth4['author'] = \"edgeworth\"\n",
    "\n",
    "df_edgeworth5 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth5['sentences'] = edgeworth_150\n",
    "df_edgeworth5['author'] = \"edgeworth\"\n",
    "\n",
    "df_edgeworth6 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth6['sentences'] = edgeworth_180\n",
    "df_edgeworth6['author'] = \"edgeworth\"\n",
    "\n",
    "df_edgeworth7 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth7['sentences'] = edgeworth_210\n",
    "df_edgeworth7['author'] = \"edgeworth\"\n",
    "\n",
    "df_edgeworth8 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth8['sentences'] = edgeworth_240\n",
    "df_edgeworth8['author'] = \"edgeworth\"\n",
    "\n",
    "df_edgeworth9 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth9['sentences'] = edgeworth_270\n",
    "df_edgeworth9['author'] = \"edgeworth\"\n",
    "\n",
    "df_edgeworth10 = pd.DataFrame(columns=column_names)\n",
    "df_edgeworth10['sentences'] = edgeworth_300\n",
    "df_edgeworth10['author'] = \"edgeworth\"\n",
    "\n",
    "\n",
    "print(df_edgeworth1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences       author\n",
      "0                                       Actus Primus  shakespeare\n",
      "1                                       Scoena Prima  shakespeare\n",
      "2   Enter Flauius, Murellus, and certaine Commone...  shakespeare\n",
      "3                                            Flauius  shakespeare\n",
      "4   Hence: home you idle Creatures, get you home:...  shakespeare\n"
     ]
    }
   ],
   "source": [
    "#creating dataframes for shakespeare\n",
    "column_names = ['sentences', \"author\"]\n",
    "\n",
    "df_shakespeare1 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare1['sentences'] = shakespeare_30\n",
    "df_shakespeare1['author'] = \"shakespeare\"\n",
    "\n",
    "df_shakespeare2 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare2['sentences'] = shakespeare_60\n",
    "df_shakespeare2['author'] = \"shakespeare\"\n",
    "\n",
    "df_shakespeare3 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare3['sentences'] = shakespeare_90\n",
    "df_shakespeare3['author'] = \"shakespeare\"\n",
    "\n",
    "df_shakespeare4 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare4['sentences'] = shakespeare_120\n",
    "df_shakespeare4['author'] = \"shakespeare\"\n",
    "\n",
    "df_shakespeare5 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare5['sentences'] = shakespeare_150\n",
    "df_shakespeare5['author'] = \"shakespeare\"\n",
    "\n",
    "df_shakespeare6 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare6['sentences'] = shakespeare_180\n",
    "df_shakespeare6['author'] = \"shakespeare\"\n",
    "\n",
    "df_shakespeare7 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare7['sentences'] = shakespeare_210\n",
    "df_shakespeare7['author'] = \"shakespeare\"\n",
    "\n",
    "df_shakespeare8 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare8['sentences'] = shakespeare_240\n",
    "df_shakespeare8['author'] = \"shakespeare\"\n",
    "\n",
    "df_shakespeare9 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare9['sentences'] = shakespeare_270\n",
    "df_shakespeare9['author'] = \"shakespeare\"\n",
    "\n",
    "df_shakespeare10 = pd.DataFrame(columns=column_names)\n",
    "df_shakespeare10['sentences'] = shakespeare_300\n",
    "df_shakespeare10['author'] = \"shakespeare\"\n",
    "\n",
    "\n",
    "print(df_shakespeare1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining each of the ten dataframes for each of the ten authors in the data, into one dataframe.\n",
    "df_combined = pd.concat([df_milton1, df_melville1, df_austen1, df_blake1, df_bryant1, df_burgess1, df_carroll1,\n",
    "                        df_chesterton1, df_edgeworth1, df_shakespeare1, df_milton2, df_melville2, df_austen2,\n",
    "                        df_blake2, df_bryant2, df_burgess2, df_carroll2, df_chesterton2, df_edgeworth2, df_shakespeare2,\n",
    "                        df_milton3, df_melville3, df_austen3, df_blake3, df_bryant3, df_burgess3, df_carroll3,\n",
    "                        df_chesterton3, df_edgeworth3, df_shakespeare3, df_milton4, df_melville4, df_austen4,\n",
    "                        df_blake4, df_bryant4, df_burgess4, df_carroll4, df_chesterton4, df_edgeworth4, df_shakespeare4,\n",
    "                        df_milton5, df_melville5, df_austen5, df_blake5, df_bryant5, df_burgess5, df_carroll5,\n",
    "                        df_chesterton5, df_edgeworth5, df_shakespeare5, df_milton6, df_melville6, df_austen6,\n",
    "                        df_blake6, df_bryant6, df_burgess6, df_carroll6, df_chesterton6, df_edgeworth6, df_shakespeare6,\n",
    "                        df_milton7, df_melville7, df_austen7, df_blake7, df_bryant7, df_burgess7, df_carroll7, \n",
    "                        df_chesterton7, df_edgeworth7, df_shakespeare7, df_milton8, df_melville8, df_austen8, \n",
    "                        df_blake8, df_bryant8, df_burgess8, df_carroll8, df_chesterton8, df_edgeworth8, df_shakespeare8,\n",
    "                        df_milton9, df_melville9, df_austen9, df_blake9, df_bryant9, df_burgess9, df_carroll9, \n",
    "                        df_chesterton9, df_edgeworth9, df_shakespeare9, df_milton10, df_melville10, df_austen10,\n",
    "                        df_blake10, df_bryant10, df_burgess10, df_carroll10, df_chesterton10, df_edgeworth10, \n",
    "                        df_shakespeare10], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2910, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences  author\n",
      "0  Of Man's first disobedience, and the fruit Of ...  milton\n",
      "1   And chiefly thou, O Spirit, that dost prefer ...  milton\n",
      "2   Say first for Heaven hides nothing from thy v...  milton\n",
      "3         Who first seduced them to that foul revolt  milton\n",
      "4   Th' infernal Serpent; he it was whose guile, ...  milton\n"
     ]
    }
   ],
   "source": [
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "austen         300\n",
       "chesterton     300\n",
       "melville       300\n",
       "burgess        300\n",
       "shakespeare    300\n",
       "bryant         300\n",
       "carroll        300\n",
       "edgeworth      300\n",
       "blake          300\n",
       "milton         210\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the data to make it completely random, after resampling\n",
    "from sklearn.utils import shuffle \n",
    "df_combined = shuffle(df_combined)\n",
    "\n",
    "#resetting index\n",
    "df_combined = df_combined.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let me see: I'll give them a new pair of boot...</td>\n",
       "      <td>carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The minute the fox reached the bank he threw ...</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There the same thing happened</td>\n",
       "      <td>burgess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These children were well thought of and pitie...</td>\n",
       "      <td>edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And\\r\\nhe is as much bigger than you as you a...</td>\n",
       "      <td>bryant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Little Joe Otter found that out when he took ...</td>\n",
       "      <td>burgess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'We won't talk about her any more if you'd ra...</td>\n",
       "      <td>carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\" GOLDSMITH TO JOHNSON</td>\n",
       "      <td>melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\" SIBBALD'S FIFE AND KINROSS</td>\n",
       "      <td>melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>chesterton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences      author\n",
       "0   Let me see: I'll give them a new pair of boot...     carroll\n",
       "1   The minute the fox reached the bank he threw ...      austen\n",
       "2                      There the same thing happened     burgess\n",
       "3   These children were well thought of and pitie...   edgeworth\n",
       "4   And\\r\\nhe is as much bigger than you as you a...      bryant\n",
       "5   Little Joe Otter found that out when he took ...     burgess\n",
       "6   'We won't talk about her any more if you'd ra...     carroll\n",
       "7                             \" GOLDSMITH TO JOHNSON    melville\n",
       "8                       \" SIBBALD'S FIFE AND KINROSS    melville\n",
       "9                                                  I  chesterton"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2910, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create corpus for the X values to put into model.\n",
    "corpus_var = df_combined['sentences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "#initiate and fit our tfidf vector\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english',\n",
    "                             lowercase=True, #convert everything to lower case\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "corpus_var_tfidf=vectorizer.fit_transform(corpus_var)\n",
    "#print(\"Number of features: %d\" % corpus_var_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(corpus_var_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Normalize the data.\n",
    "tfidf_norm = normalize(corpus_var_tfidf)\n",
    "\n",
    "tfidf_array = tfidf_norm.toarray()\n",
    "\n",
    "# Reduce it to two components.\n",
    "tfidf_pca = PCA(2).fit_transform(tfidf_array)\n",
    "\n",
    "\n",
    "#tfidf_corpusvar_array = corpus_var_tfidf.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1828</th>\n",
       "      <th>_he_</th>\n",
       "      <th>_miaouw_</th>\n",
       "      <th>_our_</th>\n",
       "      <th>_roar_</th>\n",
       "      <th>_rustle</th>\n",
       "      <th>_tap</th>\n",
       "      <th>_who</th>\n",
       "      <th>abject</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yoake</th>\n",
       "      <th>yon</th>\n",
       "      <th>yonder</th>\n",
       "      <th>young</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 2826 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1828  _he_  _miaouw_  _our_  _roar_   _rustle  _tap  _who  abject  able  \\\n",
       "0    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "1    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "2    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "3    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "4    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "5    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "6    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "7    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "8    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "9    0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "10   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "11   0.0   0.0       0.0    0.0     0.0  0.362459   0.0   0.0     0.0   0.0   \n",
       "12   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "13   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "14   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "15   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "16   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "17   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "18   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "19   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "20   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "21   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "22   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "23   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "24   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "25   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "26   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "27   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "28   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "29   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "30   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "31   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "32   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "33   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "34   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "35   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "36   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "37   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "38   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "39   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "40   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "41   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "42   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "43   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "44   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "45   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "46   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "47   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "48   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "49   0.0   0.0       0.0    0.0     0.0  0.000000   0.0   0.0     0.0   0.0   \n",
       "\n",
       "      ...     yesterday  yield  yielded  yoake  yon  yonder  young  youngest  \\\n",
       "0     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "1     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "2     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "3     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "4     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "5     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "6     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "7     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "8     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "9     ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "10    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "11    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "12    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "13    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "14    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "15    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "16    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "17    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "18    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "19    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "20    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "21    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "22    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "23    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "24    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "25    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "26    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "27    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "28    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "29    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "30    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "31    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "32    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "33    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "34    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "35    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "36    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "37    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "38    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "39    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "40    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "41    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "42    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "43    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "44    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "45    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "46    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "47    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "48    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "49    ...           0.0    0.0      0.0    0.0  0.0     0.0    0.0       0.0   \n",
       "\n",
       "    youth  youthful  \n",
       "0     0.0       0.0  \n",
       "1     0.0       0.0  \n",
       "2     0.0       0.0  \n",
       "3     0.0       0.0  \n",
       "4     0.0       0.0  \n",
       "5     0.0       0.0  \n",
       "6     0.0       0.0  \n",
       "7     0.0       0.0  \n",
       "8     0.0       0.0  \n",
       "9     0.0       0.0  \n",
       "10    0.0       0.0  \n",
       "11    0.0       0.0  \n",
       "12    0.0       0.0  \n",
       "13    0.0       0.0  \n",
       "14    0.0       0.0  \n",
       "15    0.0       0.0  \n",
       "16    0.0       0.0  \n",
       "17    0.0       0.0  \n",
       "18    0.0       0.0  \n",
       "19    0.0       0.0  \n",
       "20    0.0       0.0  \n",
       "21    0.0       0.0  \n",
       "22    0.0       0.0  \n",
       "23    0.0       0.0  \n",
       "24    0.0       0.0  \n",
       "25    0.0       0.0  \n",
       "26    0.0       0.0  \n",
       "27    0.0       0.0  \n",
       "28    0.0       0.0  \n",
       "29    0.0       0.0  \n",
       "30    0.0       0.0  \n",
       "31    0.0       0.0  \n",
       "32    0.0       0.0  \n",
       "33    0.0       0.0  \n",
       "34    0.0       0.0  \n",
       "35    0.0       0.0  \n",
       "36    0.0       0.0  \n",
       "37    0.0       0.0  \n",
       "38    0.0       0.0  \n",
       "39    0.0       0.0  \n",
       "40    0.0       0.0  \n",
       "41    0.0       0.0  \n",
       "42    0.0       0.0  \n",
       "43    0.0       0.0  \n",
       "44    0.0       0.0  \n",
       "45    0.0       0.0  \n",
       "46    0.0       0.0  \n",
       "47    0.0       0.0  \n",
       "48    0.0       0.0  \n",
       "49    0.0       0.0  \n",
       "\n",
       "[50 rows x 2826 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking feature names after tfidf\n",
    "pd.DataFrame(tfidf_array, columns=vectorizer.get_feature_names()).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#using the elbow method to get the optimum value for K\n",
    "cost =[] \n",
    "for i in range(1, 11): \n",
    "    KM_test = KMeans(n_clusters = i, max_iter = 500) \n",
    "    KM_test.fit(tfidf_norm) \n",
    "      \n",
    "    # calculates squared error \n",
    "    # for the clustered points \n",
    "    cost.append(KM_test.inertia_)    \n",
    "    \n",
    "# plot the cost against K values \n",
    "plt.plot(range(1, 11), cost, color ='g', linewidth ='3') \n",
    "plt.xlabel(\"Value of K\") \n",
    "plt.ylabel(\"Sqaured Error (Cost)\") \n",
    "plt.show() # clear the plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initializing Kmeans and predicting cluster value for each data point\n",
    "km = KMeans(n_clusters=6, init='k-means++')\n",
    "km.fit(tfidf_norm)\n",
    "\n",
    "#predicting cluster for each datapoint in the data.\n",
    "labels_pred_km = km.predict(tfidf_norm)\n",
    "\n",
    "# Plot the solution.\n",
    "plt.scatter(tfidf_pca[:, 0], tfidf_pca[:, 1], c=labels_pred_km)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column for dataframe X, containing cluster labels for each observation (datapoint) from Kmeans results.\n",
    "df_combined['ClusterNum'] = labels_pred_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>author</th>\n",
       "      <th>ClusterNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let me see: I'll give them a new pair of boot...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The minute the fox reached the bank he threw ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There the same thing happened</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These children were well thought of and pitie...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And\\r\\nhe is as much bigger than you as you a...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Little Joe Otter found that out when he took ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'We won't talk about her any more if you'd ra...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\" GOLDSMITH TO JOHNSON</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\" SIBBALD'S FIFE AND KINROSS</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Above all the globe is at unity with itself; ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>At last, there came a little rustling, whispe...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>roll around</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\r\\n\\r\\n\"Not I,\" said the Duck</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Age, thou art sham'd</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentences  author  ClusterNum\n",
       "0    Let me see: I'll give them a new pair of boot...       7           0\n",
       "1    The minute the fox reached the bank he threw ...       3           0\n",
       "2                       There the same thing happened       6           0\n",
       "3    These children were well thought of and pitie...       9           0\n",
       "4    And\\r\\nhe is as much bigger than you as you a...       5           0\n",
       "5    Little Joe Otter found that out when he took ...       6           1\n",
       "6    'We won't talk about her any more if you'd ra...       7           0\n",
       "7                              \" GOLDSMITH TO JOHNSON       2           0\n",
       "8                        \" SIBBALD'S FIFE AND KINROSS       2           0\n",
       "9                                                   I       8           0\n",
       "10   Above all the globe is at unity with itself; ...       8           0\n",
       "11   At last, there came a little rustling, whispe...       3           1\n",
       "12                                        roll around       3           0\n",
       "13                     \\r\\n\\r\\n\"Not I,\" said the Duck       5           4\n",
       "14                               Age, thou art sham'd      10           0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2335\n",
       "1     259\n",
       "4     143\n",
       "5      79\n",
       "3      69\n",
       "2      25\n",
       "Name: ClusterNum, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examining ClusterName column\n",
    "df_combined.ClusterNum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19cb08f67b8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHolJREFUeJzt3X10VPW97/H3V0AoDypIgoGAQa9iUBRIBCwu5OAB0UtFIDxVKyiWrvpw5Wi9Wrt6Cp6L5bbHKj4sW6wIVAsHUYRDKcqjKGJpQNAoKha5EKE8KYogQuL3/jE7YSAbMsBM9iT5vNbKmtm/+e09n1GS7+zf/u29zd0RERE52mlRBxARkfSkAiEiIqFUIEREJJQKhIiIhFKBEBGRUCoQIiISSgVCRERCqUCIiEgoFQgREQlVN+oAp6J58+aek5MTdQwRkWpl9erVu9w9o7J+1bpA5OTkUFhYGHUMEZFqxcz+XyL9NMQkIiKhVCBERCSUCoSIiIRK2TEIM2sALAfqB+8zy91/ZWZtgRlAM2AN8CN3P2hm9YFpQB6wGxjq7ptSlU9qt0OHDlFcXMyBAweijnJSGjRoQHZ2NvXq1Ys6itRgqTxI/S3Qy92/NrN6wJtm9lfgHuBRd59hZr8HRgFPB49fuPv/MLNhwP8FhqYwn9RixcXFNGnShJycHMws6jgnxN3ZvXs3xcXFtG3bNuo4UoOlbIjJY74OFusFPw70AmYF7VOBG4Ln/YNlgtevtur2myvVxoEDBzj77LOrXXEAMDPOPvvsarv3I9VHSo9BmFkdM1sL7AAWAv8A9rh7SdClGGgVPG8FbAEIXv8SODuV+aR2q47FoUx1zi7VR0oLhLuXuntHIBvoAuSGdQsew/7FV7gfqpmNNrNCMyvcuXNn8sKKiMgRqmQWk7vvAZYB3YCzzKzs2Ec2sDV4Xgy0BghePxP4PGRbk9w9393zMzIqPRFQpMq88sorfPDBB+XLPXv21ImcUq2lchZTBnDI3feY2feAfyV24HkpUEBsJtMIYE6wytxgeWXw+hJ3r7AHcTI2P9ShQlubf38vGZsWKffKK6/Qr18/2rdvf8rbKikpoW7dan2hA6kBUrkHkQUsNbN3gb8DC919HnA/cI+ZfULsGMOzQf9ngbOD9nuAB1KYTSQhN9xwA3l5eVx88cVMmjQJgMaNG5e/PmvWLEaOHMlbb73F3Llzue++++jYsSP/+Mc/AHjxxRfp0qULF154IW+88QYQO0B+yy230KFDBzp16sTSpUsBmDJlCoMHD+YHP/gBffr0qeJPKlJRyr6iuPu7QKeQ9o3Ejkcc3X4AGJyqPCInY/LkyTRr1oxvvvmGyy+/nEGDBoX2+/73v8/1119Pv379KCgoKG8vKSlh1apVzJ8/n3HjxrFo0SKeeuopAN577z0+/PBD+vTpw8cffwzAypUreffdd2nWrFnqP5xIJbQPK3Icjz/+OLNnzwZgy5YtbNiw4YTWHzhwIAB5eXls2rQJgDfffJO77roLgIsuuohzzz23vED07t1bxUHShgqEyDEsW7aMRYsWsXLlSho2bEjPnj05cODAEVNMKzsXoX79+gDUqVOHkpLY7O7jHVpr1KhREpKLJIeuxSRyDF9++SVNmzalYcOGfPjhh7z99tsAtGjRgvXr1/Pdd9+V710ANGnShL1791a63R49evDCCy8A8PHHH7N582batWuXmg8hcgpUIESOoW/fvpSUlHDppZfyy1/+km7dugEwYcIE+vXrR69evcjKyirvP2zYMH7729/SqVOn8oPUYW6//XZKS0vp0KEDQ4cOZcqUKeV7GiLpxJI0kzQS+fn5nsg8c01zlaOtX7+e3Nyw8zarj5rwGSQaZrba3fMr66c9CBERCaWD1Ck288UKM3oZMnhVBElERE6M9iBERCSUCoSIiIRSgRARkVA6BhF4vcdVFdquWv56BElERNKDCoQIkHfftKRub/Vvb660z6233sq8efPIzMykqKgoqe8vkgwaYhKJyMiRI1mwYEHUMUSOSQVCJCI9evTQhfkkralAiIhIKBUIEREJpYPUSTZ27NgjlttfHE0OEZFTpT0IEREJpT0IERKblppsw4cPZ9myZezatYvs7GzGjRvHqFGjqjyHyLGoQIhEZPr06VFHEDkuDTGJiEgoFQgREQmlAiEiIqF0DCICl8169YjldQXXRJREROTYtAchIiKhVCBERCRUyoaYzKw1MA04B/gOmOTuE81sLPBjYGfQ9UF3nx+s83NgFFAK/C93f7XChkVSYPNDHZK6vTb//l6lfbZs2cLNN9/MP//5T0477TRGjx7N3XffndQcIqcilccgSoB73X2NmTUBVpvZwuC1R939P+M7m1l7YBhwMdASWGRmF7p7aQozikSmbt26PPLII3Tu3Jm9e/eSl5dH7969ad++fdTRRIAUDjG5+zZ3XxM83wusB1odZ5X+wAx3/9bdPwU+AbqkKp9I1LKysujcuTMATZo0ITc3l88++yziVCKHVckxCDPLAToBfwua7jSzd81sspk1DdpaAVviVismpKCY2WgzKzSzwp07dx79ski1tGnTJt555x26du0adRSRcikvEGbWGHgJGOPuXwFPA+cDHYFtwCNlXUNW9woN7pPcPd/d8zMyMlKUWqTqfP311wwaNIjHHnuMM844I+o4IuVSWiDMrB6x4vCCu78M4O7b3b3U3b8DnuHwMFIx0Dpu9WxgayrziUTt0KFDDBo0iBtvvJGBAwdGHUfkCCkrEGZmwLPAenf/XVx7Vly3AUDZ3drnAsPMrL6ZtQUuAFalKp9I1NydUaNGkZubyz333BN1HJEKUjmLqTvwI+A9M1sbtD0IDDezjsSGjzYBPwFw9/fNbCbwAbEZUHdoBpNUlUSmpSbbihUr+NOf/kSHDh3o2LEjAA8//DDXXXddlWcRCZOyAuHubxJ+XGH+cdYZD4xPVSaRdHLllVfiXuEwm0ja0JnUIiISSgVCRERCqUCIiEgoFQgREQmlAiEiIqFUIEREJJTuKCcCdH+ie1K3t+KuFZX2OXDgAD169ODbb7+lpKSEgoICxo0bl9QcIqdCBUIkIvXr12fJkiU0btyYQ4cOceWVV3LttdfSrVu3qKOJABpiEomMmdG4cWMgdk2mQ4cOEbtCjUh6UIEQiVBpaSkdO3YkMzOT3r1763LfklZUIEQiVKdOHdauXUtxcTGrVq2iqKio8pVEqogKhEgaOOuss+jZsycLFiyIOopIORUIkYjs3LmTPXv2APDNN9+waNEiLrrooohTiRymWUynaP34JVFHkCRIZFpqsm3bto0RI0ZQWlrKd999x5AhQ+jXr1+V5xA5FhUIkYhceumlvPPOO1HHEDkmDTGJiEgoFQgREQmlAiEiIqFUIEREJJQKhIiIhFKBEBGRUJrmKgK83uOqpG7vquWvJ9y3tLSU/Px8WrVqxbx585KaQ+RUaA9CJGITJ04kNzc36hgiFahAiESouLiYv/zlL9x2221RRxGpoEYOMeXdN+2I5dlNIgoiUokxY8bwm9/8hr1790YdRaQC7UGIRGTevHlkZmaSl5cXdRSRUCkrEGbW2syWmtl6M3vfzO4O2puZ2UIz2xA8Ng3azcweN7NPzOxdM+ucqmwi6WDFihXMnTuXnJwchg0bxpIlS7jpppuijiVSLpV7ECXAve6eC3QD7jCz9sADwGJ3vwBYHCwDXAtcEPyMBp5OYTaRyP3617+muLiYTZs2MWPGDHr16sXzzz8fdSyRcik7BuHu24BtwfO9ZrYeaAX0B3oG3aYCy4D7g/Zp7u7A22Z2lpllBdsRSakTmZYqUltUyTEIM8sBOgF/A1qU/dEPHjODbq2ALXGrFQdtR29rtJkVmlnhzp07UxlbpMr07NlT50BI2kl5gTCzxsBLwBh3/+p4XUPavEKD+yR3z3f3/IyMjGTFFBGRo6S0QJhZPWLF4QV3fzlo3m5mWcHrWcCOoL0YaB23ejawNZX5RETk2FI5i8mAZ4H17v67uJfmAiOC5yOAOXHtNwezmboBX+r4g4hIdFJ5olx34EfAe2a2Nmh7EJgAzDSzUcBmYHDw2nzgOuATYD9wSwqziYhIJVI5i+lNwo8rAFwd0t+BO1KVR0RETozOpBYRkVA18lpMIifqyXv/O6nbu/ORHyTULycnhyZNmlCnTh3q1q1LYWFhUnOInAoVCJGILV26lObNm0cdQ6QCFYgTMP6mggptA3NvjyCJiEjq6RiESITMjD59+pCXl8ekSZOijiNyBO1BiERoxYoVtGzZkh07dtC7d28uuugievToEXUsEUB7ECKRatmyJQCZmZkMGDCAVatWRZxI5DAVCJGI7Nu3r/xOcvv27eO1117jkksuiTiVyGEaYhIh8WmpybR9+3YGDBgAQElJCT/84Q/p27dvlecQORYVCJGInHfeeaxbty7qGCLHpCEmEREJpQIhIiKhVCBERCRUQgXCzBYn0iYiIjXHcQ9Sm1kDoCHQ3Myacvjy3WcALVOcTUREIlTZLKafAGOIFYPVHC4QXwFPpTCXiIhE7LgFwt0nAhPN7C53f6KKMolUubALMZ6KXzw/K6F+e/bs4bbbbqOoqAgzY/LkyVxxxRVJzSJyshI6D8LdnzCz7wM58eu4+7QU5RKpFe6++2769u3LrFmzOHjwIPv37486kki5hAqEmf0JOB9YC5QGzQ6oQIicpK+++orly5czZcoUAE4//XROP/30aEOJxEn0TOp8oH1w3+gaofsT3Y9YfjjkP0Wy7zImEm/jxo1kZGRwyy23sG7dOvLy8pg4cSKNGjWKOpoIkPh5EEXAOakMIlLblJSUsGbNGn7605/yzjvv0KhRIyZMmBB1LJFyiRaI5sAHZvaqmc0t+0llMJGaLjs7m+zsbLp27QpAQUEBa9asiTiVyGGJDjGNTWUIkdronHPOoXXr1nz00Ue0a9eOxYsX0759+6hjiZRLdBbT66kOIhKlRKelJtsTTzzBjTfeyMGDBznvvPN47rnnIskhEibRWUx7ic1aAjgdqAfsc/czUhVMpDbo2LEjhYWFUccQCZXoHkST+GUzuwHokpJEIiKSFk7qaq7u/grQ63h9zGyyme0ws6K4trFm9pmZrQ1+rot77edm9omZfWRm15xMLhERSZ5Eh5gGxi2eRuy8iMrOiZgCPEnFk+kedff/PGr77YFhwMXErvu0yMwudPdSREQkEonOYoq/YW8JsAnof7wV3H25meUkuP3+wAx3/xb41Mw+ITaEtTLB9UVEJMkSPQZxSxLf804zuxkoBO519y+AVsDbcX2Kg7YKzGw0MBqgTZs2SYwlIiLxEr1hULaZzQ6OKWw3s5fMLPsk3u9pYtd06ghsAx4pe4uQvqFDWO4+yd3z3T0/IyPjJCKIiEgiEh1ieg74MzA4WL4paOt9Im/m7tvLnpvZM8C8YLEYaB3XNRvYeiLbFjkV68cvSer2cn9x3DkcAHz00UcMHTq0fHnjxo089NBDjBkzJqlZRE5WogUiw93jz+CZYmYn/K/YzLLcfVuwOIDYNZ4A5gJ/NrPfETtIfQGw6kS3L1KdtGvXjrVr1wJQWlpKq1atGDBgQMSpRA5LtEDsMrObgOnB8nBg9/FWMLPpQE9itystBn4F9DSzjsSGjzYRu2Md7v6+mc0EPiB2EPwOzWCS2mTx4sWcf/75nHvuuVFHESmXaIG4ldiU1UeJ/XF/CzjugWt3Hx7S/Oxx+o8HxieYR6RGmTFjBsOHh/3KiEQn0RPl/gMY4e4Z7p5JrGCMTVkqkVrk4MGDzJ07l8GDB1feWaQKJVogLg2mowLg7p8DnVITSaR2+etf/0rnzp1p0aJF1FFEjpBogTjNzJqWLZhZMxIfnhKR45g+fbqGlyQtJfpH/hHgLTObRewYxBB0vEBqkESmpabC/v37WbhwIX/4wx8ieX+R40n0TOppZlZI7AJ9Bgx09w9SmkykFmjYsCG7dx93QqBIZBIeJgoKgoqCiEgtcVKX+xYRkZpPBUJEREKpQIiISCgVCBERCaUCISIioXSymwgwduzYSLb36KOP8sc//hEzo0OHDjz33HM0aNAgqVlETpb2IEQi8tlnn/H4449TWFhIUVERpaWlzJgxI+pYIuVUIEQiVFJSwjfffENJSQn79++nZcuWUUcSKacCIRKRVq1a8bOf/Yw2bdqQlZXFmWeeSZ8+faKOJVJOBUIkIl988QVz5szh008/ZevWrezbt4/nn38+6lgi5VQgRCKyaNEi2rZtS0ZGBvXq1WPgwIG89dZbUccSKacCIRKRNm3a8Pbbb7N//37cncWLF5Obmxt1LJFymuYqQvKnuSaia9euFBQU0LlzZ+rWrUunTp0YPXp0lecQORYVCJEIjRs3jnHjxkUdQySUhphERCSUCoSIiIRSgRARkVAqECIiEkoFQkREQqWsQJjZZDPbYWZFcW3NzGyhmW0IHpsG7WZmj5vZJ2b2rpl1TlUuERFJTCqnuU4BngSmxbU9ACx29wlm9kCwfD9wLXBB8NMVeDp4FKkSM1/sktTtDRm8KqF+EydO5JlnnsHd+fGPf8yYMWOSmkPkVKRsD8LdlwOfH9XcH5gaPJ8K3BDXPs1j3gbOMrOsVGUTSQdFRUU888wzrFq1inXr1jFv3jw2bNgQdSyRclV9DKKFu28DCB4zg/ZWwJa4fsVBm0iNtX79erp160bDhg2pW7cuV111FbNnz446lki5dDlIbSFtHtrRbLSZFZpZ4c6dO1McSyR1LrnkEpYvX87u3bvZv38/8+fPZ8uWLZWvKFJFqvpSG9vNLMvdtwVDSDuC9mKgdVy/bGBr2AbcfRIwCSA/Pz+0iIhUB7m5udx///307t2bxo0bc9lll1G3rq5+I+mjqv81zgVGABOCxzlx7Xea2QxiB6e/LBuKkqoz/qaCI5Z/8fysiJLUHqNGjWLUqFEAPPjgg2RnZ0ecSOSwlBUIM5sO9ASam1kx8CtihWGmmY0CNgODg+7zgeuAT4D9wC2pyiWSTnbs2EFmZiabN2/m5ZdfZuXKlVFHEimXsgLh7sOP8dLVIX0duCNVWUQqk+i01GQbNGgQu3fvpl69ejz11FM0bdo0khwiYTTgKRKhN954I+oIIseULrOYREQkzahAiIhIKBUIEREJpQIhIiKhVCBERCSUCoSIiITSNFcR4LJZryZ1e+sKrqm0z6233sq8efPIzMykqCh225TPP/+coUOHsmnTJnJycpg5c6bOjZDIaA9CJCIjR45kwYIFR7RNmDCBq6++mg0bNnD11VczYcKEiNKJqECIRKZHjx40a9bsiLY5c+YwYsQIAEaMGMErr7wSRTQRQAVCJK1s376drKzYvbKysrLYsWNHJWuIpI4KhIiIhFKBEEkjLVq0YNu22JXut23bRmZmZiVriKSOCoRIGrn++uuZOjV22/apU6fSv3//iBNJbaZpriIkNi012YYPH86yZcvYtWsX2dnZjBs3jgceeIAhQ4bw7LPP0qZNG1588cUqzyVSRgVCJCLTp08PbV+8eHEVJxEJpyEmEREJpQIhIiKhNMRUQ3V/ovsRyyvuWnHE8pP3/ndVxklL7o6ZRR3jpMTu0iuSWtqDkFqpQYMG7N69u1r+oXV3du/eTYMGDaKOIjWc9iCkVsrOzqa4uJidO3dGHeWkNGjQgOzs7KhjSA2nAiG1Ur169Wjbtm3UMUTSmoaYREQklAqEiIiEUoEQEZFQKhAiIhIqkoPUZrYJ2AuUAiXunm9mzYD/AnKATcAQd/8iinwiIhLtHsS/uHtHd88Plh8AFrv7BcDiYFlERCKSTkNM/YGpwfOpwA0RZhERqfWiKhAOvGZmq81sdNDWwt23AQSPulOKiEiEojpRrru7bzWzTGChmX2Y6IpBQRkN0KZNm1TlExGp9SLZg3D3rcHjDmA20AXYbmZZAMFj6N3a3X2Su+e7e35GRkZVRRYRqXWqvECYWSMza1L2HOgDFAFzgRFBtxHAnKrOJiIih0UxxNQCmB1cZrku8Gd3X2BmfwdmmtkoYDMwOIJsIiISqPIC4e4bgctC2ncDV1d1HhERCZdO01xFRCSNqECIiEgo3Q9CRKpUZbfDhYq3xL3zkR+kNJOE0x6EiIiEUoEQEZFQKhAiIhJKBUJEREKpQIiISCgVCBERCaUCISIioXQehIhIGlo/fskRy7m/6FXlGbQHISIiobQHIXKCLpv16hHL6wquiSiJpKOadKa49iBERCSUCoSIiIRSgRARkVA6BiFSQ6XDLJiqNHbs2ITaJHEqECJSLR1dACX5NMQkIiKhVCBERCSUhphqidd7XHVkw+U/iyaIpLWjz/EAnedRm2kPQkREQqlAiIhIKA0xyTGFzRKp6VMla7LaOA105otdjlgeMnhVREmqJxUIEUl7428qqNA2MPf2CJLULioQItXA0ZMMrlr+ekRJpDZJuwJhZn2BiUAd4I/uPiHiSCJpT9+wJRXS6iC1mdUBngKuBdoDw82sfbSpRERqp3Tbg+gCfOLuGwHMbAbQH/gg0lRyTEcfBAQdCDyevPumVWhb/dubj1g++n4CAA8f9at69P0ETlaF/3/2H0nZbpnND3Wo2Nj0jKS+x4nQeR4nJt0KRCtgS9xyMdA1oiwS4uhZL+0vjiaH1BwVTuIEnciZJszdo85QzswGA9e4+23B8o+ALu5+V1yf0cDoYLEd8FEVRmwO7KrC96tq+nzVV03+bKDPl2znuntGZZ3SbQ+iGGgdt5wNbI3v4O6TgElVGaqMmRW6e34U710V9Pmqr5r82UCfLyppdZAa+DtwgZm1NbPTgWHA3IgziYjUSmm1B+HuJWZ2J/AqsWmuk939/YhjiYjUSmlVIADcfT4wP+ocxxDJ0FYV0uervmryZwN9vkik1UFqERFJH+l2DEJERNKECkSCzKyvmX1kZp+Y2QNR50kmM5tsZjvMrCjqLMlmZq3NbKmZrTez983s7qgzJZOZNTCzVWa2Lvh846LOlApmVsfM3jGzeVFnSTYz22Rm75nZWjMrjDpPPA0xJSC4BMjHQG9iU3H/Dgx39xpxhreZ9QC+Bqa5+yVR50kmM8sCstx9jZk1AVYDN9Sg/3cGNHL3r82sHvAmcLe7vx1xtKQys3uAfOAMd+8XdZ5kMrNNQL67p915HtqDSEz5JUDc/SBQdgmQGsHdlwOfR50jFdx9m7uvCZ7vBdYTO2O/RvCYr4PFesFPjfrWZ2bZwP8E/hh1ltpGBSIxYZcAqTF/ZGoLM8sBOgF/izZJcgXDL2uBHcBCd69Rnw94DPjfwHdRB0kRB14zs9XBlSLShgpEYiykrUZ9S6vpzKwx8BIwxt2/ijpPMrl7qbt3JHblgS5mVmOGCc2sH7DD3VdHnSWFurt7Z2JXsb4jGPJNCyoQian0EiCSvoKx+ZeAF9z95ajzpIq77wGWAX0jjpJM3YHrg3H6GUAvM3s+2kjJ5e5bg8cdwGxiQ9ppQQUiMboESDUVHMR9Fljv7r+LOk+ymVmGmZ0VPP8e8K/Ah9GmSh53/7m7Z7t7DrHfuyXuflPEsZLGzBoFkycws0ZAHyBtZhOqQCTA3UuAskuArAdm1qRLgJjZdGAl0M7Mis1sVNSZkqg78CNi3zzXBj/XRR0qibKApWb2LrEvMgvdvcZNBa3BWgBvmtk6YBXwF3dfEHGmcprmKiIiobQHISIioVQgREQklAqEiIiEUoEQEZFQKhAiIhJKBUJqDTM7x8xmmNk/zOwDM5tvZhee7FVszWykmbU8ifXGmtl+M8uMa/v6eOuIREEFQmqF4IS52cAydz/f3dsDDxKbh36yRgInVCDMrOwujruAe0/hvUVSTgVCaot/AQ65++/LGtx9LXEXYQz2CJ6MW55nZj2Di+FNMbOi4Lr9/2ZmBcQuP/1CcPLd98wsz8xeDy669mpwqXHMbJmZPWxmrwNl96OYDAw1s2bxIc0sJ36Pxsx+ZmZj47bzqJktD+5vcbmZvWxmG8zs/yT7P5iICoTUFpcQuxfEyegItHL3S9y9A/Ccu88CCoEbgwvllQBPAAXunkesAIyP28ZZ7n6Vuz8SLH8d9DnRGxgddPcewO+BOcAdwWcbaWZnn+TnEwlVt/IuIrXeRuA8M3sC+AvwWkifdsT+UC+MjWZRB9gW9/p/hazzOLDWzB4Jee1Yyq4B9h7wvrtvAzCzjcQuKLn7BLYlclwqEFJbvA8UVNKnhCP3qhsAuPsXZnYZcA2xb+xDgFuPWteI/cG+4hjb3nd0g7vvMbM/A7dXliHOt8Hjd3HPy5b1+yxJpSEmqS2WAPXN7MdlDWZ2OXBuXJ9NQEczO83MWhNcdtnMmgOnuftLwC+BzkH/vUCT4PlHQIaZXRGsU8/MLk4g1++An3D4j/t2INPMzjaz+kCNur2mVC/6xiG1gru7mQ0AHjOzB4ADxArCmLhuK4BPiQ3fFAFrgvZWwHNmVvaF6ufB4xTg92b2DXAFsT2Ux83sTGK/W48R23M5Xq5dZjYb+Ldg+ZCZPUTsrnefUoMu3S3Vj67mKiIioTTEJCIioVQgREQklAqEiIiEUoEQEZFQKhAiIhJKBUJEREKpQIiISCgVCBERCfX/AdPsm/P3kpYUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"ClusterNum\", hue=\"author\", data=df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['author'] = df_combined[\"author\"].map({'milton':1, \"melville\":2, \"austen\":3, \"blake\":4, \"bryant\":5, \n",
    "                                                  \"burgess\":6, \"carroll\":7, \"chesterton\":8, \"edgeworth\":9, \n",
    "                                                  \"shakespeare\":10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "0        7\n",
      "1        3\n",
      "2        6\n",
      "3        9\n",
      "4        5\n",
      "5        6\n",
      "6        7\n",
      "7        2\n",
      "8        2\n",
      "9        8\n",
      "10       8\n",
      "11       3\n",
      "12       3\n",
      "13       5\n",
      "14      10\n",
      "15       5\n",
      "16       7\n",
      "17       8\n",
      "18       9\n",
      "19       4\n",
      "20       1\n",
      "21      10\n",
      "22       8\n",
      "23       4\n",
      "24      10\n",
      "25       3\n",
      "26       2\n",
      "27      10\n",
      "28       9\n",
      "29       8\n",
      "        ..\n",
      "2880     8\n",
      "2881     9\n",
      "2882     5\n",
      "2883     5\n",
      "2884     2\n",
      "2885     9\n",
      "2886     6\n",
      "2887     7\n",
      "2888     9\n",
      "2889     7\n",
      "2890     7\n",
      "2891     6\n",
      "2892     2\n",
      "2893     7\n",
      "2894     5\n",
      "2895    10\n",
      "2896    10\n",
      "2897     4\n",
      "2898    10\n",
      "2899     4\n",
      "2900     8\n",
      "2901     5\n",
      "2902     2\n",
      "2903     5\n",
      "2904     4\n",
      "2905     9\n",
      "2906     4\n",
      "2907     2\n",
      "2908     9\n",
      "2909     2\n",
      "Name: author, Length: 2910, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#setting the output variable to be put into model.\n",
    "Y = df_combined['author']\n",
    "print(Y.dtype)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 93.08431990645244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.\n",
    "svd= TruncatedSVD(1200)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data.\n",
    "lsa_tfidf = lsa.fit_transform(corpus_var_tfidf)\n",
    "\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "#paras_by_component=pd.DataFrame(train_X_lsa,index=train_X)\n",
    "#for i in range(5):\n",
    "#    print('Component {}:'.format(i))\n",
    "#    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2328, 1200)\n",
      "(2328,)\n",
      "(582, 1200)\n",
      "(582,)\n"
     ]
    }
   ],
   "source": [
    "#creating inital train test split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(lsa_tfidf, Y, test_size=.2, random_state=2)\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infinity values in train_X:  0\n",
      "infinity values in train_Y:  0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('infinity values in train_X: ', np.isinf(train_X).sum())\n",
    "print('infinity values in train_Y: ', np.isinf(train_Y).sum())\n",
    "\n",
    "\n",
    "print(np.isnan(train_Y).any().sum())\n",
    "print(np.isnan(train_X).any().sum())\n",
    "print(np.isnan(test_Y).any().sum())\n",
    "print(np.isnan(test_X).any().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the infinite values\n",
    "X_df['Bedroom2Transformed'] = X_df['Bedroom2Transformed'].replace([np.inf, -np.inf], 6)\n",
    "\n",
    "\n",
    "#rechecking for infinity values in Bedroom2Transformed\n",
    "print('infinity values in Bedroom2Transformed: ', np.isinf(X_df['Bedroom2Transformed']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=5, score=0.3829787234042553, total=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=5, score=0.36538461538461536, total=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=5, score=0.3583690987124464, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=5, score=0.39740820734341253, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=5, score=0.3796095444685466, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=10, score=0.3872340425531915, total=   3.0s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=10, score=0.39316239316239315, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=10, score=0.3583690987124464, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=10, score=0.35853131749460043, total=   2.7s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=10, score=0.3926247288503254, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=15, score=0.3638297872340426, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=15, score=0.405982905982906, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=15, score=0.3798283261802575, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=15, score=0.38228941684665224, total=   2.7s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=700, min_samples_split=15, score=0.4229934924078091, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=5, score=0.38085106382978723, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=5, score=0.36324786324786323, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=5, score=0.3669527896995708, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=5, score=0.34557235421166305, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=5, score=0.3774403470715835, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=10, score=0.4127659574468085, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=10, score=0.3888888888888889, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=10, score=0.3626609442060086, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=10, score=0.3801295896328294, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=10, score=0.40130151843817785, total=   3.4s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=15, score=0.37659574468085105, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=15, score=0.4252136752136752, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=15, score=0.37553648068669526, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=15, score=0.3801295896328294, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=100, max_features=800, min_samples_split=15, score=0.3882863340563991, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=5, score=0.3829787234042553, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=5, score=0.36538461538461536, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=5, score=0.3583690987124464, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=5, score=0.39740820734341253, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=5, score=0.3796095444685466, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=10, score=0.3872340425531915, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=10, score=0.39316239316239315, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=10, score=0.3583690987124464, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=10, score=0.35853131749460043, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=10, score=0.3926247288503254, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=15, score=0.3638297872340426, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=15, score=0.405982905982906, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=15, score=0.3798283261802575, total=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=15, score=0.38228941684665224, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=700, min_samples_split=15, score=0.4229934924078091, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=5, score=0.38085106382978723, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=5, score=0.36324786324786323, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=5, score=0.3669527896995708, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=5, score=0.34557235421166305, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=5, score=0.3774403470715835, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=10, score=0.4127659574468085, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=10, score=0.3888888888888889, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=10, score=0.3626609442060086, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=10, score=0.3801295896328294, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=10, score=0.40130151843817785, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=15, score=0.37659574468085105, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=15, score=0.4252136752136752, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=15, score=0.37553648068669526, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=15, score=0.3801295896328294, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=entropy, max_depth=200, max_features=800, min_samples_split=15, score=0.3882863340563991, total=   3.2s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=5, score=0.38085106382978723, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=5, score=0.4252136752136752, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=5, score=0.4012875536480687, total=   0.9s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=5, score=0.4146868250539957, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=5, score=0.4164859002169197, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=10, score=0.39148936170212767, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=10, score=0.4166666666666667, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=10, score=0.39914163090128757, total=   0.9s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=10, score=0.39092872570194387, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=10, score=0.403470715835141, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=15, score=0.39361702127659576, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=15, score=0.3888888888888889, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=15, score=0.39914163090128757, total=   0.9s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=15, score=0.38876889848812096, total=   0.9s\n",
      "[CV] criterion=gini, max_depth=100, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=700, min_samples_split=15, score=0.3839479392624729, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=5, score=0.37446808510638296, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=5, score=0.391025641025641, total=   1.3s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=5, score=0.3540772532188841, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=5, score=0.4298056155507559, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=5, score=0.3752711496746204, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=10, score=0.3893617021276596, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=10, score=0.42094017094017094, total=   1.3s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=10, score=0.36909871244635195, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=10, score=0.4103671706263499, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=10, score=0.351409978308026, total=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=15, score=0.40638297872340423, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=15, score=0.3952991452991453, total=   1.3s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=15, score=0.3626609442060086, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=15, score=0.41252699784017277, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=100, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=100, max_features=800, min_samples_split=15, score=0.3969631236442516, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=5, score=0.38085106382978723, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=5, score=0.4252136752136752, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=5, score=0.4012875536480687, total=   0.9s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=5, score=0.4146868250539957, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=5, score=0.4164859002169197, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=10, score=0.39148936170212767, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=10, score=0.4166666666666667, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=10, score=0.39914163090128757, total=   0.9s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=10, score=0.39092872570194387, total=   0.9s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=10, score=0.403470715835141, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=15, score=0.39361702127659576, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=15, score=0.3888888888888889, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=15, score=0.39914163090128757, total=   0.9s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=15, score=0.38876889848812096, total=   0.9s\n",
      "[CV] criterion=gini, max_depth=200, max_features=700, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=700, min_samples_split=15, score=0.3839479392624729, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=5, score=0.37446808510638296, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=5, score=0.391025641025641, total=   1.3s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=5, score=0.3540772532188841, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=5, score=0.4298056155507559, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=5 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=5, score=0.3752711496746204, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=10, score=0.3893617021276596, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=10, score=0.42094017094017094, total=   1.3s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=10, score=0.36909871244635195, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=10, score=0.4103671706263499, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=10, score=0.351409978308026, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=15, score=0.40638297872340423, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=15, score=0.3952991452991453, total=   1.3s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=15, score=0.3626609442060086, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=15, score=0.41252699784017277, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=200, max_features=800, min_samples_split=15 \n",
      "[CV]  criterion=gini, max_depth=200, max_features=800, min_samples_split=15, score=0.3969631236442516, total=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for decision tree:  {'criterion': 'gini', 'max_depth': 100, 'max_features': 700, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "# perform grid search to find the optimal parameters for our decision tree model, using TF-IDF\n",
    "dtree = tree.DecisionTreeClassifier(random_state=76)\n",
    "tree_param_grid = {'max_depth':[100,200], 'min_samples_split':[5,10,15], 'max_features':[700,800], \n",
    "                   'criterion':['entropy', 'gini']}\n",
    "dtree_grid = GridSearchCV(dtree, tree_param_grid, cv=5, verbose=3)\n",
    "dtree_grid.fit(train_X, train_Y)\n",
    "print('Best parameters for decision tree: ', dtree_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree best score from Gridsearchcv:  0.40764604810996563\n"
     ]
    }
   ],
   "source": [
    "print('decision tree best score from Gridsearchcv: ', dtree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.38316151202749144\n",
      "Accuracy score for decision tree Model: 0.38316151202749144\n",
      "\n",
      "Duration: 0:00:01.878977\n",
      "\n",
      "[0.39862543 0.38659794 0.43298969 0.36426117 0.395189  ]\n",
      "Average cross validated score from our decision tree model is: 0.39553264604811\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train our tree using full data\n",
    "decision_tree = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_features=700,\n",
    "    max_depth=100,\n",
    "    min_samples_split=5\n",
    ")\n",
    "\n",
    "#set start time\n",
    "start_time2 = datetime.datetime.now()\n",
    "\n",
    "#train our tree\n",
    "decision_tree.fit(train_X, train_Y)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_dtree = decision_tree.predict(test_X)\n",
    "\n",
    "#Run score\n",
    "print('Score: ', decision_tree.score(test_X, test_Y))\n",
    "\n",
    "#get accuracy score from our model\n",
    "print('Accuracy score for decision tree Model: ' + str(metrics.accuracy_score(test_Y, y_pred_dtree)))\n",
    "\n",
    "#calculate end time\n",
    "end_time2 = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time2 - start_time2))\n",
    "print()\n",
    "\n",
    "#get accuracy score of decision tree\n",
    "tree_score = cross_val_score(decision_tree, lsa_tfidf, Y, cv=5, scoring='accuracy')\n",
    "print(tree_score)\n",
    "print('Average cross validated score from our decision tree model is: ' + str(np.mean(tree_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=50, score=0.5191489361702127, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=50, score=0.5427350427350427, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=50, score=0.5493562231759657, total= 1.3min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=50, score=0.5464362850971922, total= 1.3min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=50, score=0.5314533622559653, total= 1.4min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=150, score=0.5127659574468085, total= 3.7min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=150, score=0.5641025641025641, total= 3.6min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=150, score=0.5493562231759657, total= 3.7min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=150, score=0.5615550755939525, total= 3.6min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=10, n_estimators=150, score=0.5509761388286334, total= 3.8min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=50, score=0.5276595744680851, total= 1.2min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=50, score=0.5641025641025641, total= 1.2min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=50, score=0.555793991416309, total= 1.3min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=50, score=0.5464362850971922, total= 1.2min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=50, score=0.5509761388286334, total= 1.2min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=150, score=0.5212765957446809, total= 3.4min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=150, score=0.5598290598290598, total= 3.4min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=150, score=0.5515021459227468, total= 3.5min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=150, score=0.5658747300215983, total= 3.8min\n",
      "[CV] max_depth=100, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=700, min_samples_split=15, n_estimators=150, score=0.5574837310195228, total= 1.5min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=50, score=0.5063829787234042, total=  32.8s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=50, score=0.5405982905982906, total=  31.8s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=50, score=0.5407725321888412, total=  33.1s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=50, score=0.5291576673866091, total=  32.3s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=50, score=0.5054229934924078, total=  33.4s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=150, score=0.5148936170212766, total= 1.6min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=150, score=0.5470085470085471, total= 1.6min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=150, score=0.5536480686695279, total= 1.7min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=150, score=0.5529157667386609, total= 1.6min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=10, n_estimators=150, score=0.5206073752711496, total= 1.7min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=50, score=0.5127659574468085, total=  31.9s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=50, score=0.5384615384615384, total=  31.2s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=50, score=0.5407725321888412, total=  32.4s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=50, score=0.5226781857451404, total=  31.7s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=50, score=0.5401301518438177, total=  32.2s\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=150, score=0.5276595744680851, total= 1.6min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=150, score=0.5641025641025641, total= 1.6min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=150, score=0.5364806866952789, total= 1.6min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=150, score=0.5572354211663066, total= 1.6min\n",
      "[CV] max_depth=100, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=100, max_features=800, min_samples_split=15, n_estimators=150, score=0.544468546637744, total= 1.6min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=50, score=0.5191489361702127, total=  28.7s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=50, score=0.5427350427350427, total=  28.1s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=50, score=0.5493562231759657, total=  28.6s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=50 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=50, score=0.5464362850971922, total=  28.7s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=50, score=0.5314533622559653, total=  29.2s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=150, score=0.5127659574468085, total= 1.4min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=150, score=0.5641025641025641, total= 1.4min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=150, score=0.5493562231759657, total= 1.4min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=150, score=0.5615550755939525, total= 1.4min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=10, n_estimators=150, score=0.5509761388286334, total= 1.5min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=50, score=0.5276595744680851, total=  27.6s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=50, score=0.5641025641025641, total=  27.2s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=50, score=0.555793991416309, total=  28.2s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=50, score=0.5464362850971922, total=  28.0s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=50, score=0.5509761388286334, total=  28.5s\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=150, score=0.5212765957446809, total= 1.4min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=150, score=0.5598290598290598, total= 1.4min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=150, score=0.5515021459227468, total= 1.4min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=150, score=0.5658747300215983, total= 1.4min\n",
      "[CV] max_depth=200, max_features=700, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=700, min_samples_split=15, n_estimators=150, score=0.5574837310195228, total= 1.4min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=50, score=0.5063829787234042, total=  32.5s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=50, score=0.5405982905982906, total=  31.7s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=50, score=0.5407725321888412, total=  32.9s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=50, score=0.5291576673866091, total=  32.3s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=50, score=0.5054229934924078, total=  33.2s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=150, score=0.5148936170212766, total= 1.6min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=150, score=0.5470085470085471, total= 1.6min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=150, score=0.5536480686695279, total= 1.6min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=150, score=0.5529157667386609, total= 1.6min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=10, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=10, n_estimators=150, score=0.5206073752711496, total= 1.7min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=50, score=0.5127659574468085, total=  31.9s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=50, score=0.5384615384615384, total=  31.4s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=50, score=0.5407725321888412, total=  32.5s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=50, score=0.5226781857451404, total=  31.7s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=50 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=50, score=0.5401301518438177, total=  32.3s\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=150, score=0.5276595744680851, total= 1.6min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=150, score=0.5641025641025641, total= 1.6min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=150, score=0.5364806866952789, total= 1.6min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=150, score=0.5572354211663066, total= 1.6min\n",
      "[CV] max_depth=200, max_features=800, min_samples_split=15, n_estimators=150 \n",
      "[CV]  max_depth=200, max_features=800, min_samples_split=15, n_estimators=150, score=0.544468546637744, total= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 109.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=56, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [50, 150], 'max_depth': [100, 200], 'min_samples_split': [10, 15], 'max_features': [700, 800]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform grid search to find the optimal parameters for our random forest model using full data\n",
    "rforest = ensemble.RandomForestClassifier(random_state=56)\n",
    "forest_param_grid = {'n_estimators':[50,150], 'max_depth':[100,200], 'min_samples_split':[10,15], \n",
    "                     'max_features':[700,800]}\n",
    "rforest_grid = GridSearchCV(rforest, forest_param_grid, cv=5, verbose=3)\n",
    "rforest_grid.fit(train_X, train_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for random forest:  {'max_depth': 100, 'max_features': 700, 'min_samples_split': 15, 'n_estimators': 150}\n",
      "Best score for random forest:  0.5511168384879725\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters for random forest: ', rforest_grid.best_params_)\n",
    "print('Best score for random forest: ', rforest_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Random Forest Model: 0.5807560137457045\n",
      "\n",
      "Duration: 0:01:52.727260\n",
      "\n",
      "[0.57560137 0.5532646  0.52749141 0.54982818 0.53608247]\n",
      "Average cross validated score from our Random Forest Model is: 0.5484536082474227\n"
     ]
    }
   ],
   "source": [
    "#initialize and train our random forest model using full data\n",
    "rand_forest = ensemble.RandomForestClassifier(n_estimators=150, criterion='gini', max_depth=100, max_features=700,\n",
    "                                              min_samples_split=15)\n",
    "\n",
    "#set start time\n",
    "start_time3 = datetime.datetime.now()\n",
    "\n",
    "rand_forest.fit(train_X, train_Y)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_rforest = rand_forest.predict(test_X)\n",
    "\n",
    "#get accuracy score from our model\n",
    "print('Accuracy score for Random Forest Model: ' + str(metrics.accuracy_score(test_Y, y_pred_rforest)))\n",
    "\n",
    "#calculate end time\n",
    "end_time3 = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time3 - start_time3))\n",
    "print()\n",
    "\n",
    "#get average accuracy score of our random forest through cross validation\n",
    "rforest_cvs = cross_val_score(rand_forest, lsa_tfidf, Y, cv=5, scoring='accuracy')\n",
    "print(rforest_cvs)\n",
    "print('Average cross validated score from our Random Forest Model is: ' + str(np.mean(rforest_cvs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Logistic regression Model: 0.5962199312714777\n",
      "\n",
      "Duration: 0:00:17.501216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59793814 0.55498282 0.57560137 0.59278351 0.54982818]\n",
      "Average cross validated score from our log regression model is: 0.5742268041237113\n"
     ]
    }
   ],
   "source": [
    "#initialize and train our model with full data\n",
    "LogReg = LogisticRegression(C=1e9, random_state=412)\n",
    "\n",
    "#set start time\n",
    "start_time4 = datetime.datetime.now()\n",
    "\n",
    "#fit and train the model\n",
    "LogReg.fit(train_X, train_Y)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_LogReg = LogReg.predict(test_X)\n",
    "\n",
    "#get accuracy score from our model\n",
    "print('Accuracy score for Logistic regression Model: ' + str(metrics.accuracy_score(test_Y, y_pred_LogReg)))\n",
    "\n",
    "#calculate end time\n",
    "end_time4 = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time4 - start_time4))\n",
    "print()\n",
    "\n",
    "#get average accuracy score using cross validation\n",
    "LogReg_cvs = cross_val_score(LogReg, lsa_tfidf, Y, cv=5, scoring='accuracy')\n",
    "print(LogReg_cvs)\n",
    "\n",
    "print('Average cross validated score from our log regression model is: ' + str(np.mean(LogReg_cvs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.20212765957446807, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.20085470085470086, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   13.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_neighbors=5, weights=uniform ..................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-1b56a7b8cf5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_neighbors'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'distance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mKNN_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mKNN_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             train_scores = _score(estimator, X_train, y_train, scorer,\n\u001b[1;32m--> 572\u001b[1;33m                                   is_multimetric)\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    453\u001b[0m                 delayed_query(\n\u001b[0;32m    454\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 455\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m             )\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \"\"\"\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# perform grid search to find the optimal parameters for our KNN model, using full data.\n",
    "KNN = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':[5,10,15], 'weights':['uniform', 'distance']}\n",
    "KNN_grid = GridSearchCV(KNN, param_grid, cv=5, verbose=3)\n",
    "KNN_grid.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters for data:', KNN_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for KNN Model: 0.16151202749140894\n",
      "\n",
      "Duration: 0:00:02.684823\n",
      "\n",
      "[0.15635739 0.16151203 0.1580756  0.15635739 0.1580756 ]\n",
      "Average cross validated score from our KNN model is: 0.15807560137457044\n"
     ]
    }
   ],
   "source": [
    "#initialize and train our model using the training set and full data\n",
    "KNN = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "\n",
    "#set start time\n",
    "start_time6 = datetime.datetime.now()\n",
    "\n",
    "#fit and train the model\n",
    "KNN.fit(train_X,train_Y)\n",
    "\n",
    "#Make predictions using test_X, and store results in new variable\n",
    "y_pred_KNN = KNN.predict(test_X)\n",
    "\n",
    "print('Accuracy score for KNN Model: ' + str(metrics.accuracy_score(test_Y, y_pred_KNN)))\n",
    "\n",
    "#calculate end time\n",
    "end_time6 = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time6 - start_time6))\n",
    "print()\n",
    "\n",
    "\n",
    "KNN_cvs = cross_val_score(KNN, lsa_tfidf, Y, cv=5, scoring='accuracy')\n",
    "print(KNN_cvs)\n",
    "print('Average cross validated score from our KNN model is: ' + str(np.mean(KNN_cvs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for svm Model: 0.6580756013745704\n",
      "\n",
      "Duration: 0:00:48.461463\n",
      "\n",
      "[0.6443299  0.63573883 0.61683849 0.63230241 0.62027491]\n",
      "Average accuracy score from our SVM model is: 0.6298969072164948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate our model and fit the data.\n",
    "svm = SVC(kernel = 'linear', probability=True, random_state=16)\n",
    "\n",
    "#set start time\n",
    "start_time7 = datetime.datetime.now()\n",
    "\n",
    "#fit and train the model\n",
    "svm.fit(train_X, train_Y)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_svm = svm.predict(test_X)\n",
    "\n",
    "#get accuracy score from our model\n",
    "print('Accuracy score for svm Model: ' + str(metrics.accuracy_score(test_Y, y_pred_svm)))\n",
    "\n",
    "#calculate end time\n",
    "end_time7 = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time7 - start_time7))\n",
    "print()\n",
    "\n",
    "#get average accuracy score of svm model using cross validation\n",
    "svm_cvs = cross_val_score(svm, lsa_tfidf, Y, cv=5, scoring='accuracy')\n",
    "print(svm_cvs)\n",
    "print('Average accuracy score from our SVM model is: ' + str(np.mean(svm_cvs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
